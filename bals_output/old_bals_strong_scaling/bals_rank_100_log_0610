[0m[[0minfo[0m] [0mLoading project definition from /mnt/ALS_debug/project[0m
[0m[[0minfo[0m] [0mSet current project to als_debug (in build file:/mnt/ALS_debug/)[0m
[0m[[0minfo[0m] [0mRunning als_debug.Broadcast_ALS --master=spark://ec2-23-22-131-218.compute-1.amazonaws.com:7077 --jars=/mnt/ALS_debug/target/als_debug-assembly-1.0.jar --sparkhome=/root/spark --train=hdfs://ec2-23-22-131-218.compute-1.amazonaws.com:9000/data/netflix_randSplit1_data.txt --rank=100 --niter=10 --m=17770 --npslits=32 --n=480189[0m
master:       spark://ec2-23-22-131-218.compute-1.amazonaws.com:7077
train:        hdfs://ec2-23-22-131-218.compute-1.amazonaws.com:9000/data/netflix_randSplit1_data.txt
test:         
rank:         100
lambda:       0.01
niter:        10
jar:          /mnt/ALS_debug/target/als_debug-assembly-1.0.jar
sparkhome:    /root/spark
nsplits:      4
big:          false
m:            17770
n:            480189
13/06/11 00:11:52 INFO Slf4jEventHandler: Slf4jEventHandler started
13/06/11 00:11:52 INFO BlockManagerMaster: Registered BlockManagerMaster Actor
13/06/11 00:11:52 INFO MemoryStore: MemoryStore started with capacity 18.8 GB.
13/06/11 00:11:52 INFO DiskStore: Created local directory at /tmp/spark-local-20130611001152-05bf
13/06/11 00:11:52 INFO ConnectionManager: Bound socket to port 38470 with id = ConnectionManagerId(ip-10-31-129-101.ec2.internal,38470)
13/06/11 00:11:52 INFO BlockManagerMaster: Trying to register BlockManager
13/06/11 00:11:52 INFO BlockManagerMaster: Registered BlockManager
13/06/11 00:11:52 INFO HttpBroadcast: Broadcast server started at http://10.31.129.101:51831
13/06/11 00:11:52 INFO MapOutputTracker: Registered MapOutputTrackerActor actor
13/06/11 00:11:52 INFO HttpFileServer: HTTP File server directory is /tmp/spark-b6c8c2c9-8ac4-481b-b08a-de6ef7d8c232
13/06/11 00:11:53 INFO IoWorker: IoWorker thread 'spray-io-worker-0' started
13/06/11 00:11:53 INFO HttpServer: akka://spark/user/BlockManagerHTTPServer started on /0.0.0.0:50658
13/06/11 00:11:53 INFO BlockManagerUI: Started BlockManager web UI at http://ip-10-31-129-101.ec2.internal:50658
13/06/11 00:11:53 INFO SparkContext: Added JAR /mnt/ALS_debug/target/als_debug-assembly-1.0.jar at http://10.31.129.101:52757/jars/als_debug-assembly-1.0.jar with timestamp 1370909513463
13/06/11 00:11:53 INFO Client$ClientActor: Connecting to master spark://ec2-23-22-131-218.compute-1.amazonaws.com:7077
13/06/11 00:11:53 INFO SparkDeploySchedulerBackend: Connected to Spark cluster with app ID app-20130611001153-0000
13/06/11 00:11:53 INFO Client$ClientActor: Executor added: app-20130611001153-0000/0 on worker-20130611001139-ip-10-31-132-203.ec2.internal-37203 (ip-10-31-132-203.ec2.internal) with 8 cores
13/06/11 00:11:53 INFO SparkDeploySchedulerBackend: Granted executor ID app-20130611001153-0000/0 on host ip-10-31-132-203.ec2.internal with 8 cores, 40.0 GB RAM
13/06/11 00:11:53 INFO Client$ClientActor: Executor added: app-20130611001153-0000/1 on worker-20130611001139-ip-10-232-39-5.ec2.internal-56290 (ip-10-232-39-5.ec2.internal) with 8 cores
13/06/11 00:11:53 INFO SparkDeploySchedulerBackend: Granted executor ID app-20130611001153-0000/1 on host ip-10-232-39-5.ec2.internal with 8 cores, 40.0 GB RAM
13/06/11 00:11:53 INFO Client$ClientActor: Executor added: app-20130611001153-0000/2 on worker-20130611001139-ip-10-232-8-42.ec2.internal-38237 (ip-10-232-8-42.ec2.internal) with 8 cores
13/06/11 00:11:53 INFO SparkDeploySchedulerBackend: Granted executor ID app-20130611001153-0000/2 on host ip-10-232-8-42.ec2.internal with 8 cores, 40.0 GB RAM
13/06/11 00:11:53 INFO Client$ClientActor: Executor added: app-20130611001153-0000/3 on worker-20130611001139-ip-10-171-8-42.ec2.internal-34022 (ip-10-171-8-42.ec2.internal) with 8 cores
13/06/11 00:11:53 INFO SparkDeploySchedulerBackend: Granted executor ID app-20130611001153-0000/3 on host ip-10-171-8-42.ec2.internal with 8 cores, 40.0 GB RAM
13/06/11 00:11:53 INFO MemoryStore: ensureFreeSpace(45937) called with curMem=0, maxMem=20157722787
13/06/11 00:11:53 INFO MemoryStore: Block broadcast_0 stored as values to memory (estimated size 44.9 KB, free 18.8 GB)
13/06/11 00:11:53 INFO Client$ClientActor: Executor updated: app-20130611001153-0000/3 is now RUNNING
13/06/11 00:11:53 INFO Client$ClientActor: Executor updated: app-20130611001153-0000/1 is now RUNNING
13/06/11 00:11:53 INFO Client$ClientActor: Executor updated: app-20130611001153-0000/2 is now RUNNING
13/06/11 00:11:53 INFO Client$ClientActor: Executor updated: app-20130611001153-0000/0 is now RUNNING
13/06/11 00:11:54 INFO KryoSerializer: Running user registrator: als_debug.CCDKryoRegistrator
13/06/11 00:11:55 INFO SparkDeploySchedulerBackend: Registered executor: Actor[akka://sparkExecutor@ip-10-31-132-203.ec2.internal:35619/user/Executor] with ID 0
13/06/11 00:11:55 INFO SparkDeploySchedulerBackend: Registered executor: Actor[akka://sparkExecutor@ip-10-171-8-42.ec2.internal:42675/user/Executor] with ID 3
13/06/11 00:11:55 INFO SparkDeploySchedulerBackend: Registered executor: Actor[akka://sparkExecutor@ip-10-232-39-5.ec2.internal:41129/user/Executor] with ID 1
13/06/11 00:11:55 INFO SparkDeploySchedulerBackend: Registered executor: Actor[akka://sparkExecutor@ip-10-232-8-42.ec2.internal:42158/user/Executor] with ID 2
13/06/11 00:11:55 INFO BlockManagerMasterActor$BlockManagerInfo: Registering block manager ip-10-31-132-203.ec2.internal:36720 with 40.4 GB RAM
13/06/11 00:11:55 INFO BlockManagerMasterActor$BlockManagerInfo: Registering block manager ip-10-171-8-42.ec2.internal:43322 with 40.4 GB RAM
13/06/11 00:11:55 INFO BlockManagerMasterActor$BlockManagerInfo: Registering block manager ip-10-232-39-5.ec2.internal:57698 with 40.4 GB RAM
13/06/11 00:11:55 INFO BlockManagerMasterActor$BlockManagerInfo: Registering block manager ip-10-232-8-42.ec2.internal:44983 with 40.4 GB RAM
13/06/11 00:11:56 INFO MemoryStore: ensureFreeSpace(15495647) called with curMem=45937, maxMem=20157722787
13/06/11 00:11:56 INFO MemoryStore: Block broadcast_1 stored as values to memory (estimated size 14.8 MB, free 18.8 GB)
13/06/11 00:11:56 INFO MemoryStore: ensureFreeSpace(418725016) called with curMem=15541584, maxMem=20157722787
13/06/11 00:11:56 INFO MemoryStore: Block broadcast_2 stored as values to memory (estimated size 399.3 MB, free 18.4 GB)
=================================
W_b SIZE is: 17770
13/06/11 00:12:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/06/11 00:12:02 WARN LoadSnappy: Snappy native library not loaded
13/06/11 00:12:02 INFO FileInputFormat: Total input paths to process : 1
13/06/11 00:12:02 INFO NetworkTopology: Adding a new node: /default-rack/10.31.132.203:50010
13/06/11 00:12:02 INFO NetworkTopology: Adding a new node: /default-rack/10.171.8.42:50010
13/06/11 00:12:02 INFO NetworkTopology: Adding a new node: /default-rack/10.232.39.5:50010
13/06/11 00:12:02 INFO SparkContext: Starting job: reduce at BALS.scala:102
13/06/11 00:12:02 INFO DAGScheduler: Got job 0 (reduce at BALS.scala:102) with 4 output partitions (allowLocal=false)
13/06/11 00:12:02 INFO DAGScheduler: Final stage: Stage 0 (map at BALS.scala:102)
13/06/11 00:12:02 INFO DAGScheduler: Parents of final stage: List()
13/06/11 00:12:02 INFO DAGScheduler: Missing parents: List()
13/06/11 00:12:02 INFO DAGScheduler: Submitting Stage 0 (MappedRDD[4] at map at BALS.scala:102), which has no missing parents
13/06/11 00:12:02 INFO DAGScheduler: Submitting 4 missing tasks from Stage 0 (MappedRDD[4] at map at BALS.scala:102)
13/06/11 00:12:02 INFO ClusterScheduler: Adding task set 0.0 with 4 tasks
13/06/11 00:12:03 INFO TaskSetManager: Starting task 0.0:0 as TID 0 on executor 0: ip-10-31-132-203.ec2.internal (preferred)
13/06/11 00:12:03 INFO TaskSetManager: Serialized task 0.0:0 as 1744 bytes in 37 ms
13/06/11 00:12:03 INFO TaskSetManager: Starting task 0.0:2 as TID 1 on executor 1: ip-10-232-39-5.ec2.internal (preferred)
13/06/11 00:12:03 INFO TaskSetManager: Serialized task 0.0:2 as 1744 bytes in 1 ms
13/06/11 00:12:03 INFO TaskSetManager: Starting task 0.0:3 as TID 2 on executor 3: ip-10-171-8-42.ec2.internal (preferred)
13/06/11 00:12:03 INFO TaskSetManager: Serialized task 0.0:3 as 1744 bytes in 0 ms
13/06/11 00:12:03 INFO TaskSetManager: Starting task 0.0:1 as TID 3 on executor 2: ip-10-232-8-42.ec2.internal (non-preferred, not one of 10.31.132.203, 10.232.39.5, 10.171.8.42)
13/06/11 00:12:03 INFO TaskSetManager: Serialized task 0.0:1 as 1744 bytes in 0 ms
13/06/11 00:12:24 INFO BlockManagerMasterActor$BlockManagerInfo: Added rdd_3_1 in memory on ip-10-232-8-42.ec2.internal:44983 (size: 73.1 MB, free: 40.4 GB)
13/06/11 00:12:24 INFO BlockManagerMasterActor$BlockManagerInfo: Added rdd_3_3 in memory on ip-10-171-8-42.ec2.internal:43322 (size: 73.1 MB, free: 40.4 GB)
13/06/11 00:12:24 INFO BlockManagerMasterActor$BlockManagerInfo: Added rdd_3_0 in memory on ip-10-31-132-203.ec2.internal:36720 (size: 73.4 MB, free: 40.4 GB)
13/06/11 00:12:24 INFO BlockManagerMasterActor$BlockManagerInfo: Added rdd_3_2 in memory on ip-10-232-39-5.ec2.internal:57698 (size: 73.1 MB, free: 40.4 GB)
13/06/11 00:12:24 INFO TaskSetManager: Finished TID 3 in 21665 ms (progress: 1/4)
13/06/11 00:12:24 INFO DAGScheduler: Completed ResultTask(0, 1)
13/06/11 00:12:24 INFO TaskSetManager: Finished TID 2 in 21690 ms (progress: 2/4)
13/06/11 00:12:24 INFO DAGScheduler: Completed ResultTask(0, 3)
13/06/11 00:12:24 INFO TaskSetManager: Finished TID 0 in 21890 ms (progress: 3/4)
13/06/11 00:12:24 INFO DAGScheduler: Completed ResultTask(0, 0)
13/06/11 00:12:24 INFO TaskSetManager: Finished TID 1 in 21884 ms (progress: 4/4)
13/06/11 00:12:24 INFO DAGScheduler: Completed ResultTask(0, 2)
13/06/11 00:12:24 INFO DAGScheduler: Stage 0 (map at BALS.scala:102) finished in 21.925 s
13/06/11 00:12:24 INFO SparkContext: Job finished: reduce at BALS.scala:102, took 21.962492802 s
MAX ROW: 17769
13/06/11 00:12:24 INFO SparkContext: Starting job: reduce at BALS.scala:103
13/06/11 00:12:24 INFO DAGScheduler: Got job 1 (reduce at BALS.scala:103) with 4 output partitions (allowLocal=false)
13/06/11 00:12:24 INFO DAGScheduler: Final stage: Stage 1 (map at BALS.scala:103)
13/06/11 00:12:24 INFO DAGScheduler: Parents of final stage: List()
13/06/11 00:12:24 INFO DAGScheduler: Missing parents: List()
13/06/11 00:12:24 INFO DAGScheduler: Submitting Stage 1 (MappedRDD[5] at map at BALS.scala:103), which has no missing parents
13/06/11 00:12:24 INFO DAGScheduler: Submitting 4 missing tasks from Stage 1 (MappedRDD[5] at map at BALS.scala:103)
13/06/11 00:12:24 INFO ClusterScheduler: Adding task set 1.0 with 4 tasks
13/06/11 00:12:24 INFO TaskSetManager: Starting task 1.0:0 as TID 4 on executor 0: ip-10-31-132-203.ec2.internal (preferred)
13/06/11 00:12:24 INFO TaskSetManager: Serialized task 1.0:0 as 1747 bytes in 4 ms
13/06/11 00:12:24 INFO TaskSetManager: Starting task 1.0:2 as TID 5 on executor 1: ip-10-232-39-5.ec2.internal (preferred)
13/06/11 00:12:24 INFO TaskSetManager: Serialized task 1.0:2 as 1747 bytes in 1 ms
13/06/11 00:12:24 INFO TaskSetManager: Starting task 1.0:3 as TID 6 on executor 3: ip-10-171-8-42.ec2.internal (preferred)
13/06/11 00:12:24 INFO TaskSetManager: Serialized task 1.0:3 as 1747 bytes in 0 ms
13/06/11 00:12:24 INFO TaskSetManager: Starting task 1.0:1 as TID 7 on executor 2: ip-10-232-8-42.ec2.internal (preferred)
13/06/11 00:12:24 INFO TaskSetManager: Serialized task 1.0:1 as 1747 bytes in 0 ms
13/06/11 00:12:26 INFO TaskSetManager: Finished TID 5 in 1800 ms (progress: 1/4)
13/06/11 00:12:26 INFO DAGScheduler: Completed ResultTask(1, 2)
13/06/11 00:12:26 INFO TaskSetManager: Finished TID 6 in 1801 ms (progress: 2/4)
13/06/11 00:12:26 INFO DAGScheduler: Completed ResultTask(1, 3)
13/06/11 00:12:26 INFO TaskSetManager: Finished TID 7 in 1808 ms (progress: 3/4)
13/06/11 00:12:26 INFO DAGScheduler: Completed ResultTask(1, 1)
13/06/11 00:12:26 INFO TaskSetManager: Finished TID 4 in 1963 ms (progress: 4/4)
13/06/11 00:12:26 INFO DAGScheduler: Completed ResultTask(1, 0)
13/06/11 00:12:26 INFO DAGScheduler: Stage 1 (map at BALS.scala:103) finished in 1.963 s
13/06/11 00:12:26 INFO SparkContext: Job finished: reduce at BALS.scala:103, took 1.966995805 s
MAX COL: 84382
13/06/11 00:12:26 INFO SparkContext: Starting job: count at BALS.scala:104
13/06/11 00:12:26 INFO DAGScheduler: Got job 2 (count at BALS.scala:104) with 4 output partitions (allowLocal=false)
13/06/11 00:12:26 INFO DAGScheduler: Final stage: Stage 2 (map at BALS.scala:70)
13/06/11 00:12:26 INFO DAGScheduler: Parents of final stage: List()
13/06/11 00:12:26 INFO DAGScheduler: Missing parents: List()
13/06/11 00:12:26 INFO DAGScheduler: Submitting Stage 2 (MappedRDD[3] at map at BALS.scala:70), which has no missing parents
13/06/11 00:12:26 INFO DAGScheduler: Submitting 4 missing tasks from Stage 2 (MappedRDD[3] at map at BALS.scala:70)
13/06/11 00:12:26 INFO ClusterScheduler: Adding task set 2.0 with 4 tasks
13/06/11 00:12:26 INFO TaskSetManager: Starting task 2.0:0 as TID 8 on executor 0: ip-10-31-132-203.ec2.internal (preferred)
13/06/11 00:12:26 INFO TaskSetManager: Serialized task 2.0:0 as 1702 bytes in 3 ms
13/06/11 00:12:26 INFO TaskSetManager: Starting task 2.0:2 as TID 9 on executor 1: ip-10-232-39-5.ec2.internal (preferred)
13/06/11 00:12:26 INFO TaskSetManager: Serialized task 2.0:2 as 1702 bytes in 0 ms
13/06/11 00:12:26 INFO TaskSetManager: Starting task 2.0:3 as TID 10 on executor 3: ip-10-171-8-42.ec2.internal (preferred)
13/06/11 00:12:26 INFO TaskSetManager: Serialized task 2.0:3 as 1702 bytes in 0 ms
13/06/11 00:12:26 INFO TaskSetManager: Starting task 2.0:1 as TID 11 on executor 2: ip-10-232-8-42.ec2.internal (preferred)
13/06/11 00:12:26 INFO TaskSetManager: Serialized task 2.0:1 as 1702 bytes in 1 ms
13/06/11 00:12:28 INFO TaskSetManager: Finished TID 11 in 1409 ms (progress: 1/4)
13/06/11 00:12:28 INFO DAGScheduler: Completed ResultTask(2, 1)
13/06/11 00:12:28 INFO TaskSetManager: Finished TID 9 in 1425 ms (progress: 2/4)
13/06/11 00:12:28 INFO DAGScheduler: Completed ResultTask(2, 2)
13/06/11 00:12:28 INFO TaskSetManager: Finished TID 10 in 1476 ms (progress: 3/4)
13/06/11 00:12:28 INFO DAGScheduler: Completed ResultTask(2, 3)
13/06/11 00:12:28 INFO TaskSetManager: Finished TID 8 in 1553 ms (progress: 4/4)
13/06/11 00:12:28 INFO DAGScheduler: Completed ResultTask(2, 0)
13/06/11 00:12:28 INFO DAGScheduler: Stage 2 (map at BALS.scala:70) finished in 1.553 s
13/06/11 00:12:28 INFO SparkContext: Job finished: count at BALS.scala:104, took 1.55596989 s
NNZ : 17600139
13/06/11 00:12:28 INFO SparkContext: Starting job: count at BALS.scala:105
13/06/11 00:12:28 INFO DAGScheduler: Got job 3 (count at BALS.scala:105) with 4 output partitions (allowLocal=false)
13/06/11 00:12:28 INFO DAGScheduler: Final stage: Stage 3 (map at BALS.scala:70)
13/06/11 00:12:28 INFO DAGScheduler: Parents of final stage: List()
13/06/11 00:12:28 INFO DAGScheduler: Missing parents: List()
13/06/11 00:12:28 INFO DAGScheduler: Submitting Stage 3 (MappedRDD[3] at map at BALS.scala:70), which has no missing parents
13/06/11 00:12:28 INFO DAGScheduler: Submitting 4 missing tasks from Stage 3 (MappedRDD[3] at map at BALS.scala:70)
13/06/11 00:12:28 INFO ClusterScheduler: Adding task set 3.0 with 4 tasks
13/06/11 00:12:28 INFO TaskSetManager: Starting task 3.0:0 as TID 12 on executor 0: ip-10-31-132-203.ec2.internal (preferred)
13/06/11 00:12:28 INFO TaskSetManager: Serialized task 3.0:0 as 1702 bytes in 2 ms
13/06/11 00:12:28 INFO TaskSetManager: Starting task 3.0:2 as TID 13 on executor 1: ip-10-232-39-5.ec2.internal (preferred)
13/06/11 00:12:28 INFO TaskSetManager: Serialized task 3.0:2 as 1702 bytes in 1 ms
13/06/11 00:12:28 INFO TaskSetManager: Starting task 3.0:3 as TID 14 on executor 3: ip-10-171-8-42.ec2.internal (preferred)
13/06/11 00:12:28 INFO TaskSetManager: Serialized task 3.0:3 as 1702 bytes in 1 ms
13/06/11 00:12:28 INFO TaskSetManager: Starting task 3.0:1 as TID 15 on executor 2: ip-10-232-8-42.ec2.internal (preferred)
13/06/11 00:12:28 INFO TaskSetManager: Serialized task 3.0:1 as 1702 bytes in 0 ms
13/06/11 00:12:29 INFO TaskSetManager: Finished TID 13 in 1424 ms (progress: 1/4)
13/06/11 00:12:29 INFO DAGScheduler: Completed ResultTask(3, 2)
13/06/11 00:12:29 INFO TaskSetManager: Finished TID 15 in 1430 ms (progress: 2/4)
13/06/11 00:12:29 INFO DAGScheduler: Completed ResultTask(3, 1)
13/06/11 00:12:29 INFO TaskSetManager: Finished TID 14 in 1490 ms (progress: 3/4)
13/06/11 00:12:29 INFO DAGScheduler: Completed ResultTask(3, 3)
13/06/11 00:12:30 INFO TaskSetManager: Finished TID 12 in 1559 ms (progress: 4/4)
13/06/11 00:12:30 INFO DAGScheduler: Completed ResultTask(3, 0)
13/06/11 00:12:30 INFO DAGScheduler: Stage 3 (map at BALS.scala:70) finished in 1.560 s
13/06/11 00:12:30 INFO SparkContext: Job finished: count at BALS.scala:105, took 1.56257084 s
Iteration: 0
13/06/11 00:12:30 INFO SparkContext: Starting job: collect at BALS.scala:117
13/06/11 00:12:30 INFO DAGScheduler: Registering RDD 7 (reduceByKey at BALS.scala:116)
13/06/11 00:12:30 INFO DAGScheduler: Got job 4 (collect at BALS.scala:117) with 4 output partitions (allowLocal=false)
13/06/11 00:12:30 INFO DAGScheduler: Final stage: Stage 4 (map at BALS.scala:117)
13/06/11 00:12:30 INFO DAGScheduler: Parents of final stage: List(Stage 5)
13/06/11 00:12:30 INFO DAGScheduler: Missing parents: List(Stage 5)
13/06/11 00:12:30 INFO DAGScheduler: Submitting Stage 5 (MapPartitionsRDD[7] at reduceByKey at BALS.scala:116), which has no missing parents
13/06/11 00:12:30 INFO DAGScheduler: Submitting 4 missing tasks from Stage 5 (MapPartitionsRDD[7] at reduceByKey at BALS.scala:116)
13/06/11 00:12:30 INFO ClusterScheduler: Adding task set 5.0 with 4 tasks
13/06/11 00:12:30 INFO TaskSetManager: Starting task 5.0:0 as TID 16 on executor 0: ip-10-31-132-203.ec2.internal (preferred)
13/06/11 00:12:30 INFO TaskSetManager: Serialized task 5.0:0 as 2214 bytes in 19 ms
13/06/11 00:12:30 INFO TaskSetManager: Starting task 5.0:2 as TID 17 on executor 1: ip-10-232-39-5.ec2.internal (preferred)
13/06/11 00:12:30 INFO TaskSetManager: Serialized task 5.0:2 as 2214 bytes in 0 ms
13/06/11 00:12:30 INFO TaskSetManager: Starting task 5.0:3 as TID 18 on executor 3: ip-10-171-8-42.ec2.internal (preferred)
13/06/11 00:12:30 INFO TaskSetManager: Serialized task 5.0:3 as 2214 bytes in 0 ms
13/06/11 00:12:30 INFO TaskSetManager: Starting task 5.0:1 as TID 19 on executor 2: ip-10-232-8-42.ec2.internal (preferred)
13/06/11 00:12:30 INFO TaskSetManager: Serialized task 5.0:1 as 2214 bytes in 0 ms
13/06/11 00:18:34 INFO TaskSetManager: Finished TID 19 in 364267 ms (progress: 1/4)
13/06/11 00:18:34 INFO DAGScheduler: Completed ShuffleMapTask(5, 1)
13/06/11 00:18:34 INFO TaskSetManager: Finished TID 17 in 364818 ms (progress: 2/4)
13/06/11 00:18:34 INFO DAGScheduler: Completed ShuffleMapTask(5, 2)
13/06/11 00:18:38 INFO TaskSetManager: Finished TID 18 in 368714 ms (progress: 3/4)
13/06/11 00:18:38 INFO DAGScheduler: Completed ShuffleMapTask(5, 3)
13/06/11 00:18:43 INFO TaskSetManager: Finished TID 16 in 373898 ms (progress: 4/4)
13/06/11 00:18:43 INFO DAGScheduler: Completed ShuffleMapTask(5, 0)
13/06/11 00:18:43 INFO DAGScheduler: Stage 5 (reduceByKey at BALS.scala:116) finished in 373.899 s
13/06/11 00:18:43 INFO DAGScheduler: looking for newly runnable stages
13/06/11 00:18:43 INFO DAGScheduler: running: Set()
13/06/11 00:18:43 INFO DAGScheduler: waiting: Set(Stage 4)
13/06/11 00:18:43 INFO DAGScheduler: failed: Set()
13/06/11 00:18:43 INFO DAGScheduler: Missing parents for Stage 4: List()
13/06/11 00:18:43 INFO DAGScheduler: Submitting Stage 4 (MappedRDD[10] at map at BALS.scala:117), which is now runnable
13/06/11 00:18:43 INFO DAGScheduler: Submitting 4 missing tasks from Stage 4 (MappedRDD[10] at map at BALS.scala:117)
13/06/11 00:18:43 INFO ClusterScheduler: Adding task set 4.0 with 4 tasks
13/06/11 00:18:43 INFO TaskSetManager: Starting task 4.0:0 as TID 20 on executor 0: ip-10-31-132-203.ec2.internal (preferred)
13/06/11 00:18:43 INFO TaskSetManager: Serialized task 4.0:0 as 2665 bytes in 8 ms
13/06/11 00:18:43 INFO TaskSetManager: Starting task 4.0:1 as TID 21 on executor 1: ip-10-232-39-5.ec2.internal (preferred)
13/06/11 00:18:43 INFO TaskSetManager: Serialized task 4.0:1 as 2665 bytes in 0 ms
13/06/11 00:18:43 INFO TaskSetManager: Starting task 4.0:2 as TID 22 on executor 3: ip-10-171-8-42.ec2.internal (preferred)
13/06/11 00:18:43 INFO TaskSetManager: Serialized task 4.0:2 as 2665 bytes in 0 ms
13/06/11 00:18:43 INFO TaskSetManager: Starting task 4.0:3 as TID 23 on executor 2: ip-10-232-8-42.ec2.internal (preferred)
13/06/11 00:18:43 INFO TaskSetManager: Serialized task 4.0:3 as 2665 bytes in 0 ms
13/06/11 00:18:44 INFO MapOutputTrackerActor: Asked to send map output locations for shuffle 0 to ip-10-232-39-5.ec2.internal
13/06/11 00:18:44 INFO MapOutputTracker: Size of output statuses for shuffle 0 is 191 bytes
13/06/11 00:18:44 INFO MapOutputTrackerActor: Asked to send map output locations for shuffle 0 to ip-10-31-132-203.ec2.internal
13/06/11 00:18:44 INFO MapOutputTrackerActor: Asked to send map output locations for shuffle 0 to ip-10-171-8-42.ec2.internal
13/06/11 00:18:44 INFO MapOutputTrackerActor: Asked to send map output locations for shuffle 0 to ip-10-232-8-42.ec2.internal
13/06/11 00:18:57 INFO TaskSetManager: Finished TID 21 in 13495 ms (progress: 1/4)
13/06/11 00:18:57 INFO DAGScheduler: Completed ResultTask(4, 1)
13/06/11 00:18:58 INFO TaskSetManager: Finished TID 20 in 14733 ms (progress: 2/4)
13/06/11 00:18:58 INFO DAGScheduler: Completed ResultTask(4, 0)
13/06/11 00:19:01 INFO TaskSetManager: Finished TID 23 in 17333 ms (progress: 3/4)
13/06/11 00:19:01 INFO DAGScheduler: Completed ResultTask(4, 3)
13/06/11 00:19:01 INFO TaskSetManager: Finished TID 22 in 17575 ms (progress: 4/4)
13/06/11 00:19:01 INFO DAGScheduler: Completed ResultTask(4, 2)
13/06/11 00:19:01 INFO DAGScheduler: Stage 4 (map at BALS.scala:117) finished in 17.595 s
13/06/11 00:19:01 INFO SparkContext: Job finished: collect at BALS.scala:117, took 391.514273015 s
13/06/11 00:19:01 INFO MemoryStore: ensureFreeSpace(15495647) called with curMem=434266600, maxMem=20157722787
13/06/11 00:19:01 INFO MemoryStore: Block broadcast_3 stored as values to memory (estimated size 14.8 MB, free 18.4 GB)
13/06/11 00:19:01 INFO SparkContext: Starting job: collect at BALS.scala:128
13/06/11 00:19:01 INFO DAGScheduler: Registering RDD 12 (reduceByKey at BALS.scala:127)
13/06/11 00:19:01 INFO DAGScheduler: Got job 5 (collect at BALS.scala:128) with 4 output partitions (allowLocal=false)
13/06/11 00:19:01 INFO DAGScheduler: Final stage: Stage 6 (map at BALS.scala:128)
13/06/11 00:19:01 INFO DAGScheduler: Parents of final stage: List(Stage 7)
13/06/11 00:19:01 INFO DAGScheduler: Missing parents: List(Stage 7)
13/06/11 00:19:01 INFO DAGScheduler: Submitting Stage 7 (MapPartitionsRDD[12] at reduceByKey at BALS.scala:127), which has no missing parents
13/06/11 00:19:01 INFO DAGScheduler: Submitting 4 missing tasks from Stage 7 (MapPartitionsRDD[12] at reduceByKey at BALS.scala:127)
13/06/11 00:19:01 INFO ClusterScheduler: Adding task set 7.0 with 4 tasks
13/06/11 00:19:01 INFO TaskSetManager: Starting task 7.0:0 as TID 24 on executor 0: ip-10-31-132-203.ec2.internal (preferred)
13/06/11 00:19:01 INFO TaskSetManager: Serialized task 7.0:0 as 2216 bytes in 4 ms
13/06/11 00:19:01 INFO TaskSetManager: Starting task 7.0:2 as TID 25 on executor 1: ip-10-232-39-5.ec2.internal (preferred)
13/06/11 00:19:01 INFO TaskSetManager: Serialized task 7.0:2 as 2216 bytes in 0 ms
13/06/11 00:19:01 INFO TaskSetManager: Starting task 7.0:3 as TID 26 on executor 3: ip-10-171-8-42.ec2.internal (preferred)
13/06/11 00:19:01 INFO TaskSetManager: Serialized task 7.0:3 as 2216 bytes in 0 ms
13/06/11 00:19:01 INFO TaskSetManager: Starting task 7.0:1 as TID 27 on executor 2: ip-10-232-8-42.ec2.internal (preferred)
13/06/11 00:19:01 INFO TaskSetManager: Serialized task 7.0:1 as 2216 bytes in 1 ms
13/06/11 00:24:21 INFO TaskSetManager: Finished TID 25 in 319697 ms (progress: 1/4)
13/06/11 00:24:21 INFO DAGScheduler: Completed ShuffleMapTask(7, 2)
13/06/11 00:24:22 INFO TaskSetManager: Finished TID 27 in 320846 ms (progress: 2/4)
13/06/11 00:24:22 INFO DAGScheduler: Completed ShuffleMapTask(7, 1)
13/06/11 00:24:26 INFO TaskSetManager: Finished TID 26 in 325064 ms (progress: 3/4)
13/06/11 00:24:26 INFO DAGScheduler: Completed ShuffleMapTask(7, 3)
13/06/11 00:24:33 INFO TaskSetManager: Finished TID 24 in 331933 ms (progress: 4/4)
13/06/11 00:24:33 INFO DAGScheduler: Completed ShuffleMapTask(7, 0)
13/06/11 00:24:33 INFO DAGScheduler: Stage 7 (reduceByKey at BALS.scala:127) finished in 331.933 s
13/06/11 00:24:33 INFO DAGScheduler: looking for newly runnable stages
13/06/11 00:24:33 INFO DAGScheduler: running: Set()
13/06/11 00:24:33 INFO DAGScheduler: waiting: Set(Stage 6)
13/06/11 00:24:33 INFO DAGScheduler: failed: Set()
13/06/11 00:24:33 INFO DAGScheduler: Missing parents for Stage 6: List()
13/06/11 00:24:33 INFO DAGScheduler: Submitting Stage 6 (MappedRDD[15] at map at BALS.scala:128), which is now runnable
13/06/11 00:24:33 INFO DAGScheduler: Submitting 4 missing tasks from Stage 6 (MappedRDD[15] at map at BALS.scala:128)
13/06/11 00:24:33 INFO ClusterScheduler: Adding task set 6.0 with 4 tasks
13/06/11 00:24:33 INFO TaskSetManager: Starting task 6.0:0 as TID 28 on executor 0: ip-10-31-132-203.ec2.internal (preferred)
13/06/11 00:24:33 INFO TaskSetManager: Serialized task 6.0:0 as 2668 bytes in 5 ms
13/06/11 00:24:33 INFO TaskSetManager: Starting task 6.0:1 as TID 29 on executor 1: ip-10-232-39-5.ec2.internal (preferred)
13/06/11 00:24:33 INFO TaskSetManager: Serialized task 6.0:1 as 2668 bytes in 0 ms
13/06/11 00:24:33 INFO TaskSetManager: Starting task 6.0:2 as TID 30 on executor 3: ip-10-171-8-42.ec2.internal (preferred)
13/06/11 00:24:33 INFO TaskSetManager: Serialized task 6.0:2 as 2668 bytes in 0 ms
13/06/11 00:24:33 INFO TaskSetManager: Starting task 6.0:3 as TID 31 on executor 2: ip-10-232-8-42.ec2.internal (preferred)
13/06/11 00:24:33 INFO TaskSetManager: Serialized task 6.0:3 as 2668 bytes in 0 ms
13/06/11 00:24:33 INFO MapOutputTrackerActor: Asked to send map output locations for shuffle 1 to ip-10-31-132-203.ec2.internal
13/06/11 00:24:33 INFO MapOutputTracker: Size of output statuses for shuffle 1 is 195 bytes
13/06/11 00:24:33 INFO MapOutputTrackerActor: Asked to send map output locations for shuffle 1 to ip-10-232-39-5.ec2.internal
13/06/11 00:24:33 INFO MapOutputTrackerActor: Asked to send map output locations for shuffle 1 to ip-10-171-8-42.ec2.internal
13/06/11 00:24:33 INFO MapOutputTrackerActor: Asked to send map output locations for shuffle 1 to ip-10-232-8-42.ec2.internal
13/06/11 00:24:59 INFO SparkDeploySchedulerBackend: Executor 3 disconnected, so removing it
13/06/11 00:24:59 ERROR ClusterScheduler: Lost executor 3 on ip-10-171-8-42.ec2.internal: remote Akka client shutdown
13/06/11 00:24:59 INFO TaskSetManager: Re-queueing tasks for 3 from TaskSet 6.0
13/06/11 00:24:59 INFO TaskSetManager: Lost TID 30 (task 6.0:2)
13/06/11 00:24:59 INFO TaskSetManager: Starting task 6.0:2 as TID 32 on executor 0: ip-10-31-132-203.ec2.internal (preferred)
13/06/11 00:24:59 INFO TaskSetManager: Serialized task 6.0:2 as 2668 bytes in 1 ms
13/06/11 00:24:59 INFO DAGScheduler: Executor lost: 3 (generation 2)
13/06/11 00:24:59 INFO BlockManagerMasterActor: Trying to remove executor 3 from BlockManagerMaster.
13/06/11 00:24:59 INFO BlockManagerMaster: Removed 3 successfully in removeExecutor
13/06/11 00:24:59 INFO Stage: Stage 7 is now unavailable on executor 3 (3/4, false)
13/06/11 00:24:59 INFO Stage: Stage 5 is now unavailable on executor 3 (3/4, false)
13/06/11 00:25:00 INFO SparkDeploySchedulerBackend: Executor 2 disconnected, so removing it
13/06/11 00:25:00 ERROR ClusterScheduler: Lost executor 2 on ip-10-232-8-42.ec2.internal: remote Akka client shutdown
13/06/11 00:25:00 INFO TaskSetManager: Re-queueing tasks for 2 from TaskSet 6.0
13/06/11 00:25:00 INFO TaskSetManager: Lost TID 31 (task 6.0:3)
13/06/11 00:25:00 INFO DAGScheduler: Executor lost: 2 (generation 4)
13/06/11 00:25:00 INFO TaskSetManager: Starting task 6.0:3 as TID 33 on executor 0: ip-10-31-132-203.ec2.internal (preferred)
13/06/11 00:25:00 INFO BlockManagerMasterActor: Trying to remove executor 2 from BlockManagerMaster.
13/06/11 00:25:00 INFO BlockManagerMaster: Removed 2 successfully in removeExecutor
13/06/11 00:25:00 INFO TaskSetManager: Serialized task 6.0:3 as 2668 bytes in 0 ms
13/06/11 00:25:00 INFO Stage: Stage 7 is now unavailable on executor 2 (2/4, false)
13/06/11 00:25:00 INFO Stage: Stage 5 is now unavailable on executor 2 (2/4, false)
13/06/11 00:25:02 INFO Client$ClientActor: Executor updated: app-20130611001153-0000/3 is now FAILED (Command exited with code 1)
13/06/11 00:25:02 INFO SparkDeploySchedulerBackend: Executor app-20130611001153-0000/3 removed: Command exited with code 1
13/06/11 00:25:02 INFO Client$ClientActor: Executor added: app-20130611001153-0000/4 on worker-20130611001139-ip-10-171-8-42.ec2.internal-34022 (ip-10-171-8-42.ec2.internal) with 8 cores
13/06/11 00:25:02 INFO SparkDeploySchedulerBackend: Granted executor ID app-20130611001153-0000/4 on host ip-10-171-8-42.ec2.internal with 8 cores, 40.0 GB RAM
13/06/11 00:25:02 INFO Client$ClientActor: Executor updated: app-20130611001153-0000/4 is now RUNNING
13/06/11 00:25:02 INFO TaskSetManager: Lost TID 33 (task 6.0:3)
13/06/11 00:25:02 INFO TaskSetManager: Loss was due to fetch failure from BlockManagerId(3, ip-10-171-8-42.ec2.internal, 43322)
13/06/11 00:25:02 INFO DAGScheduler: Marking Stage 6 (map at BALS.scala:128) for resubmision due to a fetch failure
13/06/11 00:25:02 INFO DAGScheduler: The failed fetch was from Stage 7 (reduceByKey at BALS.scala:127); marking it for resubmission
13/06/11 00:25:02 INFO ClusterScheduler: Ignoring update from TID 32 because its task set is gone
13/06/11 00:25:02 INFO Client$ClientActor: Executor updated: app-20130611001153-0000/2 is now FAILED (Command exited with code 1)
13/06/11 00:25:02 INFO SparkDeploySchedulerBackend: Executor app-20130611001153-0000/2 removed: Command exited with code 1
13/06/11 00:25:02 INFO Client$ClientActor: Executor added: app-20130611001153-0000/5 on worker-20130611001139-ip-10-232-8-42.ec2.internal-38237 (ip-10-232-8-42.ec2.internal) with 8 cores
13/06/11 00:25:02 INFO SparkDeploySchedulerBackend: Granted executor ID app-20130611001153-0000/5 on host ip-10-232-8-42.ec2.internal with 8 cores, 40.0 GB RAM
13/06/11 00:25:02 INFO DAGScheduler: Resubmitting failed stages
13/06/11 00:25:02 INFO DAGScheduler: Submitting Stage 7 (MapPartitionsRDD[12] at reduceByKey at BALS.scala:127), which has no missing parents
13/06/11 00:25:02 INFO DAGScheduler: Submitting 2 missing tasks from Stage 7 (MapPartitionsRDD[12] at reduceByKey at BALS.scala:127)
13/06/11 00:25:02 INFO ClusterScheduler: Adding task set 7.1 with 2 tasks
13/06/11 00:25:02 INFO TaskSetManager: Starting task 7.1:0 as TID 34 on executor 0: ip-10-31-132-203.ec2.internal (non-preferred, not one of 10.31.132.203, 10.232.39.5, 10.171.8.42)
13/06/11 00:25:02 INFO TaskSetManager: Serialized task 7.1:0 as 2216 bytes in 0 ms
13/06/11 00:25:02 INFO TaskSetManager: Starting task 7.1:1 as TID 35 on executor 1: ip-10-232-39-5.ec2.internal (preferred)
13/06/11 00:25:02 INFO TaskSetManager: Serialized task 7.1:1 as 2216 bytes in 0 ms
13/06/11 00:25:02 INFO Client$ClientActor: Executor updated: app-20130611001153-0000/5 is now RUNNING
13/06/11 00:25:04 INFO SparkDeploySchedulerBackend: Registered executor: Actor[akka://sparkExecutor@ip-10-171-8-42.ec2.internal:55295/user/Executor] with ID 4
13/06/11 00:25:04 INFO SparkDeploySchedulerBackend: Executor 0 disconnected, so removing it
13/06/11 00:25:04 ERROR ClusterScheduler: Lost executor 0 on ip-10-31-132-203.ec2.internal: remote Akka client shutdown
13/06/11 00:25:04 INFO TaskSetManager: Re-queueing tasks for 0 from TaskSet 7.1
13/06/11 00:25:04 INFO TaskSetManager: Lost TID 34 (task 7.1:0)
13/06/11 00:25:04 INFO DAGScheduler: Executor lost: 0 (generation 7)
13/06/11 00:25:04 INFO TaskSetManager: Starting task 7.1:0 as TID 36 on executor 1: ip-10-232-39-5.ec2.internal (non-preferred, not one of 10.31.132.203, 10.232.39.5, 10.171.8.42)
13/06/11 00:25:04 INFO BlockManagerMasterActor: Trying to remove executor 0 from BlockManagerMaster.
13/06/11 00:25:04 INFO BlockManagerMaster: Removed 0 successfully in removeExecutor
13/06/11 00:25:04 INFO TaskSetManager: Serialized task 7.1:0 as 2216 bytes in 1 ms
13/06/11 00:25:04 INFO Stage: Stage 7 is now unavailable on executor 0 (1/4, false)
13/06/11 00:25:04 INFO Stage: Stage 5 is now unavailable on executor 0 (1/4, false)
13/06/11 00:25:04 ERROR StandaloneSchedulerBackend$DriverActor: key not found: 0
java.util.NoSuchElementException: key not found: 0
	at scala.collection.MapLike$class.default(MapLike.scala:225)
	at scala.collection.mutable.HashMap.default(HashMap.scala:45)
	at scala.collection.MapLike$class.apply(MapLike.scala:135)
	at scala.collection.mutable.HashMap.apply(HashMap.scala:45)
	at spark.scheduler.cluster.StandaloneSchedulerBackend$DriverActor$$anonfun$receive$1.apply(StandaloneSchedulerBackend.scala:60)
	at spark.scheduler.cluster.StandaloneSchedulerBackend$DriverActor$$anonfun$receive$1.apply(StandaloneSchedulerBackend.scala:39)
	at akka.actor.Actor$class.apply(Actor.scala:318)
	at spark.scheduler.cluster.StandaloneSchedulerBackend$DriverActor.apply(StandaloneSchedulerBackend.scala:26)
	at akka.actor.ActorCell.invoke(ActorCell.scala:626)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:197)
	at akka.dispatch.Mailbox.run(Mailbox.scala:179)
	at akka.dispatch.ForkJoinExecutorConfigurator$MailboxExecutionTask.exec(AbstractDispatcher.scala:516)
	at akka.jsr166y.ForkJoinTask.doExec(ForkJoinTask.java:259)
	at akka.jsr166y.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:975)
	at akka.jsr166y.ForkJoinPool.runWorker(ForkJoinPool.java:1479)
	at akka.jsr166y.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:104)
13/06/11 00:25:04 INFO SparkDeploySchedulerBackend: Registered executor: Actor[akka://sparkExecutor@ip-10-232-8-42.ec2.internal:34025/user/Executor] with ID 5
13/06/11 00:25:04 INFO BlockManagerMasterActor$BlockManagerInfo: Registering block manager ip-10-171-8-42.ec2.internal:60506 with 40.4 GB RAM
13/06/11 00:25:04 INFO BlockManagerMasterActor$BlockManagerInfo: Registering block manager ip-10-232-8-42.ec2.internal:40786 with 40.4 GB RAM
13/06/11 00:25:04 INFO TaskSetManager: Lost TID 36 (task 7.1:0)
13/06/11 00:25:04 INFO TaskSetManager: Loss was due to java.io.IOException: Filesystem closed
	at org.apache.hadoop.hdfs.DFSClient.checkOpen(DFSClient.java:264)
	at org.apache.hadoop.hdfs.DFSClient.access$1100(DFSClient.java:74)
	at org.apache.hadoop.hdfs.DFSClient$DFSInputStream.read(DFSClient.java:2213)
	at java.io.DataInputStream.read(DataInputStream.java:100)
	at org.apache.hadoop.util.LineReader.readLine(LineReader.java:134)
	at org.apache.hadoop.mapred.LineRecordReader.next(LineRecordReader.java:133)
	at org.apache.hadoop.mapred.LineRecordReader.next(LineRecordReader.java:38)
	at spark.rdd.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:84)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:400)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:400)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:400)
	at scala.collection.Iterator$class.foreach(Iterator.scala:772)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:399)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:48)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:102)
	at spark.CacheManager.getOrCompute(CacheManager.scala:53)
	at spark.RDD.iterator(RDD.scala:193)
	at spark.rdd.MappedRDD.compute(MappedRDD.scala:12)
	at spark.RDD.computeOrReadCheckpoint(RDD.scala:206)
	at spark.RDD.iterator(RDD.scala:195)
	at spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:19)
	at spark.RDD.computeOrReadCheckpoint(RDD.scala:206)
	at spark.RDD.iterator(RDD.scala:195)
	at spark.scheduler.ShuffleMapTask.run(ShuffleMapTask.scala:125)
	at spark.scheduler.ShuffleMapTask.run(ShuffleMapTask.scala:74)
	at spark.executor.Executor$TaskRunner.run(Executor.scala:101)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1146)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:679)
13/06/11 00:25:04 ERROR StandaloneSchedulerBackend$DriverActor: key not found: 1
java.util.NoSuchElementException: key not found: 1
	at scala.collection.MapLike$class.default(MapLike.scala:225)
	at scala.collection.mutable.HashMap.default(HashMap.scala:45)
	at scala.collection.MapLike$class.apply(MapLike.scala:135)
	at scala.collection.mutable.HashMap.apply(HashMap.scala:45)
	at spark.scheduler.cluster.StandaloneSchedulerBackend$DriverActor$$anonfun$receive$1.apply(StandaloneSchedulerBackend.scala:60)
	at spark.scheduler.cluster.StandaloneSchedulerBackend$DriverActor$$anonfun$receive$1.apply(StandaloneSchedulerBackend.scala:39)
	at akka.actor.Actor$class.apply(Actor.scala:318)
	at spark.scheduler.cluster.StandaloneSchedulerBackend$DriverActor.apply(StandaloneSchedulerBackend.scala:26)
	at akka.actor.ActorCell.invoke(ActorCell.scala:626)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:197)
	at akka.dispatch.Mailbox.run(Mailbox.scala:179)
	at akka.dispatch.ForkJoinExecutorConfigurator$MailboxExecutionTask.exec(AbstractDispatcher.scala:516)
	at akka.jsr166y.ForkJoinTask.doExec(ForkJoinTask.java:259)
	at akka.jsr166y.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:975)
	at akka.jsr166y.ForkJoinPool.runWorker(ForkJoinPool.java:1479)
	at akka.jsr166y.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:104)
13/06/11 00:25:04 INFO TaskSetManager: Lost TID 35 (task 7.1:1)
13/06/11 00:25:04 INFO TaskSetManager: Loss was due to java.io.IOException: Filesystem closed [duplicate 1]
13/06/11 00:25:04 ERROR StandaloneSchedulerBackend$DriverActor: key not found: 1
java.util.NoSuchElementException: key not found: 1
	at scala.collection.MapLike$class.default(MapLike.scala:225)
	at scala.collection.mutable.HashMap.default(HashMap.scala:45)
	at scala.collection.MapLike$class.apply(MapLike.scala:135)
	at scala.collection.mutable.HashMap.apply(HashMap.scala:45)
	at spark.scheduler.cluster.StandaloneSchedulerBackend$DriverActor$$anonfun$receive$1.apply(StandaloneSchedulerBackend.scala:60)
	at spark.scheduler.cluster.StandaloneSchedulerBackend$DriverActor$$anonfun$receive$1.apply(StandaloneSchedulerBackend.scala:39)
	at akka.actor.Actor$class.apply(Actor.scala:318)
	at spark.scheduler.cluster.StandaloneSchedulerBackend$DriverActor.apply(StandaloneSchedulerBackend.scala:26)
	at akka.actor.ActorCell.invoke(ActorCell.scala:626)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:197)
	at akka.dispatch.Mailbox.run(Mailbox.scala:179)
	at akka.dispatch.ForkJoinExecutorConfigurator$MailboxExecutionTask.exec(AbstractDispatcher.scala:516)
	at akka.jsr166y.ForkJoinTask.doExec(ForkJoinTask.java:259)
	at akka.jsr166y.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:975)
	at akka.jsr166y.ForkJoinPool.runWorker(ForkJoinPool.java:1479)
	at akka.jsr166y.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:104)
13/06/11 00:25:06 INFO Client$ClientActor: Executor updated: app-20130611001153-0000/0 is now FAILED (Command exited with code 1)
13/06/11 00:25:06 INFO SparkDeploySchedulerBackend: Executor app-20130611001153-0000/0 removed: Command exited with code 1
13/06/11 00:25:06 INFO Client$ClientActor: Executor added: app-20130611001153-0000/6 on worker-20130611001139-ip-10-31-132-203.ec2.internal-37203 (ip-10-31-132-203.ec2.internal) with 8 cores
13/06/11 00:25:06 INFO SparkDeploySchedulerBackend: Granted executor ID app-20130611001153-0000/6 on host ip-10-31-132-203.ec2.internal with 8 cores, 40.0 GB RAM
13/06/11 00:25:06 INFO Client$ClientActor: Executor updated: app-20130611001153-0000/6 is now RUNNING
13/06/11 00:25:07 INFO Client$ClientActor: Executor updated: app-20130611001153-0000/1 is now FAILED (Command exited with code 1)
13/06/11 00:25:07 INFO SparkDeploySchedulerBackend: Executor app-20130611001153-0000/1 removed: Command exited with code 1
13/06/11 00:25:07 INFO Client$ClientActor: Executor added: app-20130611001153-0000/7 on worker-20130611001139-ip-10-232-39-5.ec2.internal-56290 (ip-10-232-39-5.ec2.internal) with 8 cores
13/06/11 00:25:07 INFO SparkDeploySchedulerBackend: Granted executor ID app-20130611001153-0000/7 on host ip-10-232-39-5.ec2.internal with 8 cores, 40.0 GB RAM
13/06/11 00:25:07 INFO Client$ClientActor: Executor updated: app-20130611001153-0000/7 is now RUNNING
13/06/11 00:25:08 INFO SparkDeploySchedulerBackend: Registered executor: Actor[akka://sparkExecutor@ip-10-31-132-203.ec2.internal:47483/user/Executor] with ID 6
13/06/11 00:25:08 INFO TaskSetManager: Starting task 7.1:0 as TID 37 on executor 6: ip-10-31-132-203.ec2.internal (non-preferred, not one of 10.31.132.203, 10.232.39.5, 10.171.8.42)
13/06/11 00:25:08 INFO TaskSetManager: Serialized task 7.1:0 as 2216 bytes in 0 ms
13/06/11 00:25:08 INFO TaskSetManager: Starting task 7.1:1 as TID 38 on executor 6: ip-10-31-132-203.ec2.internal (non-preferred, not one of ip-10-171-8-42.ec2.internal, ip-10-232-39-5.ec2.internal, ip-10-232-8-42.ec2.internal)
13/06/11 00:25:08 INFO TaskSetManager: Serialized task 7.1:1 as 2216 bytes in 0 ms
13/06/11 00:25:08 INFO BlockManagerMasterActor$BlockManagerInfo: Registering block manager ip-10-31-132-203.ec2.internal:57417 with 40.4 GB RAM
13/06/11 00:25:09 INFO SparkDeploySchedulerBackend: Registered executor: Actor[akka://sparkExecutor@ip-10-232-39-5.ec2.internal:57365/user/Executor] with ID 7
13/06/11 00:25:09 INFO BlockManagerMasterActor$BlockManagerInfo: Registering block manager ip-10-232-39-5.ec2.internal:60755 with 40.4 GB RAM
13/06/11 00:25:27 INFO BlockManagerMasterActor$BlockManagerInfo: Added rdd_3_1 in memory on ip-10-31-132-203.ec2.internal:57417 (size: 73.1 MB, free: 40.4 GB)
13/06/11 00:25:28 INFO BlockManagerMasterActor$BlockManagerInfo: Added rdd_3_3 in memory on ip-10-31-132-203.ec2.internal:57417 (size: 73.1 MB, free: 40.3 GB)
