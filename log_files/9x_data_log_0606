[0m[[0minfo[0m] [0mLoading project definition from /mnt/ALS_debug/project[0m
[0m[[0minfo[0m] [0mSet current project to als_debug (in build file:/mnt/ALS_debug/)[0m
[0m[[0minfo[0m] [0mRunning als_debug.Join_ALS --blocked=true --master=spark://ec2-23-20-33-228.compute-1.amazonaws.com:7077 --jars=/mnt/ALS_debug/target/als_debug-assembly-1.0.jar --sparkhome=/root/spark --train=hdfs://ec2-23-20-33-228.compute-1.amazonaws.com:9000/data/netflix_randSplit1_data.txt --rank=10 --niter=10 --m=17770 --npslits=32 --repfact=4 --n=480189[0m
master:       spark://ec2-23-20-33-228.compute-1.amazonaws.com:7077
train:        hdfs://ec2-23-20-33-228.compute-1.amazonaws.com:9000/data/netflix_randSplit1_data.txt
test:         
rank:         10
lambda:       0.01
niter:        10
jar:          /mnt/ALS_debug/target/als_debug-assembly-1.0.jar
sparkhome:    /root/spark
nsplits:      4
repfact:          4
m:            17770
n:            480189
blocked:      true
13/06/07 22:24:58 INFO Slf4jEventHandler: Slf4jEventHandler started
13/06/07 22:24:58 INFO BlockManagerMaster: Registered BlockManagerMaster Actor
13/06/07 22:24:58 INFO MemoryStore: MemoryStore started with capacity 18.8 GB.
13/06/07 22:24:58 INFO DiskStore: Created local directory at /tmp/spark-local-20130607222458-6b1e
13/06/07 22:24:58 INFO ConnectionManager: Bound socket to port 48935 with id = ConnectionManagerId(ip-10-29-141-239.ec2.internal,48935)
13/06/07 22:24:58 INFO BlockManagerMaster: Trying to register BlockManager
13/06/07 22:24:58 INFO BlockManagerMaster: Registered BlockManager
13/06/07 22:24:58 INFO HttpBroadcast: Broadcast server started at http://10.29.141.239:55873
13/06/07 22:24:58 INFO MapOutputTracker: Registered MapOutputTrackerActor actor
13/06/07 22:24:58 INFO HttpFileServer: HTTP File server directory is /tmp/spark-84a92ab7-f061-4368-a3de-5edc566c93dd
13/06/07 22:24:58 INFO IoWorker: IoWorker thread 'spray-io-worker-0' started
13/06/07 22:24:59 INFO HttpServer: akka://spark/user/BlockManagerHTTPServer started on /0.0.0.0:58928
13/06/07 22:24:59 INFO BlockManagerUI: Started BlockManager web UI at http://ip-10-29-141-239.ec2.internal:58928
13/06/07 22:24:59 INFO SparkContext: Added JAR /mnt/ALS_debug/target/als_debug-assembly-1.0.jar at http://10.29.141.239:43197/jars/als_debug-assembly-1.0.jar with timestamp 1370643899206
13/06/07 22:24:59 INFO Client$ClientActor: Connecting to master spark://ec2-23-20-33-228.compute-1.amazonaws.com:7077
13/06/07 22:24:59 INFO SparkDeploySchedulerBackend: Connected to Spark cluster with app ID app-20130607222459-0001
13/06/07 22:24:59 INFO Client$ClientActor: Executor added: app-20130607222459-0001/0 on worker-20130607204453-ip-10-29-181-214-59792 (ip-10-29-181-214) with 8 cores
13/06/07 22:24:59 INFO SparkDeploySchedulerBackend: Granted executor ID app-20130607222459-0001/0 on host ip-10-29-181-214 with 8 cores, 40.0 GB RAM
13/06/07 22:24:59 INFO Client$ClientActor: Executor added: app-20130607222459-0001/1 on worker-20130607204445-ip-10-232-24-231.ec2.internal-50756 (ip-10-232-24-231.ec2.internal) with 8 cores
13/06/07 22:24:59 INFO SparkDeploySchedulerBackend: Granted executor ID app-20130607222459-0001/1 on host ip-10-232-24-231.ec2.internal with 8 cores, 40.0 GB RAM
13/06/07 22:24:59 INFO Client$ClientActor: Executor added: app-20130607222459-0001/2 on worker-20130607204455-ip-10-168-23-243.ec2.internal-55701 (ip-10-168-23-243.ec2.internal) with 8 cores
13/06/07 22:24:59 INFO SparkDeploySchedulerBackend: Granted executor ID app-20130607222459-0001/2 on host ip-10-168-23-243.ec2.internal with 8 cores, 40.0 GB RAM
13/06/07 22:24:59 INFO Client$ClientActor: Executor added: app-20130607222459-0001/3 on worker-20130607204440-ip-10-232-24-207.ec2.internal-60756 (ip-10-232-24-207.ec2.internal) with 8 cores
13/06/07 22:24:59 INFO SparkDeploySchedulerBackend: Granted executor ID app-20130607222459-0001/3 on host ip-10-232-24-207.ec2.internal with 8 cores, 40.0 GB RAM
13/06/07 22:24:59 INFO Client$ClientActor: Executor updated: app-20130607222459-0001/1 is now RUNNING
13/06/07 22:24:59 INFO Client$ClientActor: Executor updated: app-20130607222459-0001/2 is now RUNNING
13/06/07 22:24:59 INFO Client$ClientActor: Executor updated: app-20130607222459-0001/3 is now RUNNING
13/06/07 22:24:59 INFO MemoryStore: ensureFreeSpace(45937) called with curMem=0, maxMem=20157722787
13/06/07 22:24:59 INFO MemoryStore: Block broadcast_0 stored as values to memory (estimated size 44.9 KB, free 18.8 GB)
13/06/07 22:24:59 INFO KryoSerializer: Running user registrator: als_debug.CCDKryoRegistrator
13/06/07 22:24:59 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/06/07 22:24:59 WARN LoadSnappy: Snappy native library not loaded
13/06/07 22:25:00 INFO FileInputFormat: Total input paths to process : 1
Number of splits in trainData: 16
Running blocked als
13/06/07 22:25:00 INFO CoGroupedRDD: Adding one-to-one dependency with MapPartitionsRDD[21] at groupByKey at new_Join_ALS.scala:203
13/06/07 22:25:00 INFO CoGroupedRDD: Adding one-to-one dependency with MapPartitionsWithIndexRDD[12] at mapPartitionsWithIndex at new_Join_ALS.scala:44
13/06/07 22:25:00 INFO CoGroupedRDD: Adding one-to-one dependency with MapPartitionsRDD[32] at groupByKey at new_Join_ALS.scala:203
13/06/07 22:25:00 INFO CoGroupedRDD: Adding one-to-one dependency with MapPartitionsWithIndexRDD[10] at mapPartitionsWithIndex at new_Join_ALS.scala:44
13/06/07 22:25:00 INFO CoGroupedRDD: Adding one-to-one dependency with MapPartitionsRDD[43] at groupByKey at new_Join_ALS.scala:203
13/06/07 22:25:00 INFO CoGroupedRDD: Adding one-to-one dependency with MapPartitionsWithIndexRDD[12] at mapPartitionsWithIndex at new_Join_ALS.scala:44
13/06/07 22:25:00 INFO CoGroupedRDD: Adding one-to-one dependency with MapPartitionsRDD[54] at groupByKey at new_Join_ALS.scala:203
13/06/07 22:25:00 INFO CoGroupedRDD: Adding one-to-one dependency with MapPartitionsWithIndexRDD[10] at mapPartitionsWithIndex at new_Join_ALS.scala:44
13/06/07 22:25:00 INFO CoGroupedRDD: Adding one-to-one dependency with MapPartitionsRDD[65] at groupByKey at new_Join_ALS.scala:203
13/06/07 22:25:00 INFO CoGroupedRDD: Adding one-to-one dependency with MapPartitionsWithIndexRDD[12] at mapPartitionsWithIndex at new_Join_ALS.scala:44
13/06/07 22:25:00 INFO CoGroupedRDD: Adding one-to-one dependency with MapPartitionsRDD[76] at groupByKey at new_Join_ALS.scala:203
13/06/07 22:25:00 INFO CoGroupedRDD: Adding one-to-one dependency with MapPartitionsWithIndexRDD[10] at mapPartitionsWithIndex at new_Join_ALS.scala:44
13/06/07 22:25:00 INFO CoGroupedRDD: Adding one-to-one dependency with MapPartitionsRDD[87] at groupByKey at new_Join_ALS.scala:203
13/06/07 22:25:00 INFO CoGroupedRDD: Adding one-to-one dependency with MapPartitionsWithIndexRDD[12] at mapPartitionsWithIndex at new_Join_ALS.scala:44
13/06/07 22:25:00 INFO CoGroupedRDD: Adding one-to-one dependency with MapPartitionsRDD[98] at groupByKey at new_Join_ALS.scala:203
13/06/07 22:25:00 INFO CoGroupedRDD: Adding one-to-one dependency with MapPartitionsWithIndexRDD[10] at mapPartitionsWithIndex at new_Join_ALS.scala:44
13/06/07 22:25:00 INFO CoGroupedRDD: Adding one-to-one dependency with MapPartitionsRDD[109] at groupByKey at new_Join_ALS.scala:203
13/06/07 22:25:00 INFO CoGroupedRDD: Adding one-to-one dependency with MapPartitionsWithIndexRDD[12] at mapPartitionsWithIndex at new_Join_ALS.scala:44
13/06/07 22:25:00 INFO CoGroupedRDD: Adding one-to-one dependency with MapPartitionsRDD[120] at groupByKey at new_Join_ALS.scala:203
13/06/07 22:25:00 INFO CoGroupedRDD: Adding one-to-one dependency with MapPartitionsWithIndexRDD[10] at mapPartitionsWithIndex at new_Join_ALS.scala:44
13/06/07 22:25:00 INFO CoGroupedRDD: Adding one-to-one dependency with MapPartitionsRDD[131] at groupByKey at new_Join_ALS.scala:203
13/06/07 22:25:00 INFO CoGroupedRDD: Adding one-to-one dependency with MapPartitionsWithIndexRDD[12] at mapPartitionsWithIndex at new_Join_ALS.scala:44
13/06/07 22:25:00 INFO CoGroupedRDD: Adding one-to-one dependency with MapPartitionsRDD[142] at groupByKey at new_Join_ALS.scala:203
13/06/07 22:25:00 INFO CoGroupedRDD: Adding one-to-one dependency with MapPartitionsWithIndexRDD[10] at mapPartitionsWithIndex at new_Join_ALS.scala:44
13/06/07 22:25:00 INFO CoGroupedRDD: Adding one-to-one dependency with MapPartitionsRDD[153] at groupByKey at new_Join_ALS.scala:203
13/06/07 22:25:00 INFO CoGroupedRDD: Adding one-to-one dependency with MapPartitionsWithIndexRDD[12] at mapPartitionsWithIndex at new_Join_ALS.scala:44
13/06/07 22:25:00 INFO CoGroupedRDD: Adding one-to-one dependency with MapPartitionsRDD[164] at groupByKey at new_Join_ALS.scala:203
13/06/07 22:25:00 INFO CoGroupedRDD: Adding one-to-one dependency with MapPartitionsWithIndexRDD[10] at mapPartitionsWithIndex at new_Join_ALS.scala:44
13/06/07 22:25:00 INFO CoGroupedRDD: Adding one-to-one dependency with MapPartitionsRDD[175] at groupByKey at new_Join_ALS.scala:203
13/06/07 22:25:00 INFO CoGroupedRDD: Adding one-to-one dependency with MapPartitionsWithIndexRDD[12] at mapPartitionsWithIndex at new_Join_ALS.scala:44
13/06/07 22:25:00 INFO CoGroupedRDD: Adding one-to-one dependency with MapPartitionsRDD[186] at groupByKey at new_Join_ALS.scala:203
13/06/07 22:25:00 INFO CoGroupedRDD: Adding one-to-one dependency with MapPartitionsWithIndexRDD[10] at mapPartitionsWithIndex at new_Join_ALS.scala:44
13/06/07 22:25:00 INFO CoGroupedRDD: Adding one-to-one dependency with MapPartitionsRDD[197] at groupByKey at new_Join_ALS.scala:203
13/06/07 22:25:00 INFO CoGroupedRDD: Adding one-to-one dependency with MapPartitionsWithIndexRDD[12] at mapPartitionsWithIndex at new_Join_ALS.scala:44
13/06/07 22:25:00 INFO CoGroupedRDD: Adding one-to-one dependency with MapPartitionsRDD[208] at groupByKey at new_Join_ALS.scala:203
13/06/07 22:25:00 INFO CoGroupedRDD: Adding one-to-one dependency with MapPartitionsWithIndexRDD[10] at mapPartitionsWithIndex at new_Join_ALS.scala:44
13/06/07 22:25:00 INFO CoGroupedRDD: Adding one-to-one dependency with MapPartitionsRDD[219] at groupByKey at new_Join_ALS.scala:203
13/06/07 22:25:00 INFO CoGroupedRDD: Adding one-to-one dependency with MapPartitionsWithIndexRDD[12] at mapPartitionsWithIndex at new_Join_ALS.scala:44
13/06/07 22:25:00 INFO CoGroupedRDD: Adding one-to-one dependency with MapPartitionsRDD[230] at groupByKey at new_Join_ALS.scala:203
13/06/07 22:25:00 INFO CoGroupedRDD: Adding one-to-one dependency with MapPartitionsWithIndexRDD[10] at mapPartitionsWithIndex at new_Join_ALS.scala:44
13/06/07 22:25:00 INFO CoGroupedRDD: Adding one-to-one dependency with MappedValuesRDD[234] at mapValues at new_Join_ALS.scala:205
13/06/07 22:25:00 INFO CoGroupedRDD: Adding one-to-one dependency with MapPartitionsWithIndexRDD[9] at mapPartitionsWithIndex at new_Join_ALS.scala:28
13/06/07 22:25:00 INFO SparkContext: Starting job: sum at new_Join_ALS.scala:514
13/06/07 22:25:00 INFO DAGScheduler: Registering RDD 228 (groupByKey at new_Join_ALS.scala:203)
13/06/07 22:25:00 INFO CoGroupedRDD: Adding one-to-one dependency with MapPartitionsWithIndexRDD[11] at mapPartitionsWithIndex at new_Join_ALS.scala:28
13/06/07 22:25:00 INFO CoGroupedRDD: Adding one-to-one dependency with MappedValuesRDD[223] at mapValues at new_Join_ALS.scala:205
13/06/07 22:25:00 INFO DAGScheduler: Registering RDD 7 (map at new_Join_ALS.scala:68)
13/06/07 22:25:00 INFO DAGScheduler: Registering RDD 217 (groupByKey at new_Join_ALS.scala:203)
13/06/07 22:25:00 INFO CoGroupedRDD: Adding one-to-one dependency with MapPartitionsWithIndexRDD[9] at mapPartitionsWithIndex at new_Join_ALS.scala:28
13/06/07 22:25:00 INFO CoGroupedRDD: Adding one-to-one dependency with MappedValuesRDD[212] at mapValues at new_Join_ALS.scala:205
13/06/07 22:25:00 INFO DAGScheduler: Registering RDD 5 (map at new_Join_ALS.scala:67)
13/06/07 22:25:00 INFO DAGScheduler: Registering RDD 206 (groupByKey at new_Join_ALS.scala:203)
13/06/07 22:25:00 INFO CoGroupedRDD: Adding one-to-one dependency with MapPartitionsWithIndexRDD[11] at mapPartitionsWithIndex at new_Join_ALS.scala:28
13/06/07 22:25:00 INFO CoGroupedRDD: Adding one-to-one dependency with MappedValuesRDD[201] at mapValues at new_Join_ALS.scala:205
13/06/07 22:25:00 INFO DAGScheduler: Registering RDD 195 (groupByKey at new_Join_ALS.scala:203)
13/06/07 22:25:00 INFO CoGroupedRDD: Adding one-to-one dependency with MapPartitionsWithIndexRDD[9] at mapPartitionsWithIndex at new_Join_ALS.scala:28
13/06/07 22:25:00 INFO CoGroupedRDD: Adding one-to-one dependency with MappedValuesRDD[190] at mapValues at new_Join_ALS.scala:205
13/06/07 22:25:00 INFO DAGScheduler: Registering RDD 184 (groupByKey at new_Join_ALS.scala:203)
13/06/07 22:25:00 INFO CoGroupedRDD: Adding one-to-one dependency with MapPartitionsWithIndexRDD[11] at mapPartitionsWithIndex at new_Join_ALS.scala:28
13/06/07 22:25:00 INFO CoGroupedRDD: Adding one-to-one dependency with MappedValuesRDD[179] at mapValues at new_Join_ALS.scala:205
13/06/07 22:25:00 INFO DAGScheduler: Registering RDD 173 (groupByKey at new_Join_ALS.scala:203)
13/06/07 22:25:00 INFO CoGroupedRDD: Adding one-to-one dependency with MapPartitionsWithIndexRDD[9] at mapPartitionsWithIndex at new_Join_ALS.scala:28
13/06/07 22:25:00 INFO CoGroupedRDD: Adding one-to-one dependency with MappedValuesRDD[168] at mapValues at new_Join_ALS.scala:205
13/06/07 22:25:00 INFO DAGScheduler: Registering RDD 162 (groupByKey at new_Join_ALS.scala:203)
13/06/07 22:25:00 INFO CoGroupedRDD: Adding one-to-one dependency with MapPartitionsWithIndexRDD[11] at mapPartitionsWithIndex at new_Join_ALS.scala:28
13/06/07 22:25:00 INFO CoGroupedRDD: Adding one-to-one dependency with MappedValuesRDD[157] at mapValues at new_Join_ALS.scala:205
13/06/07 22:25:00 INFO DAGScheduler: Registering RDD 151 (groupByKey at new_Join_ALS.scala:203)
13/06/07 22:25:00 INFO CoGroupedRDD: Adding one-to-one dependency with MapPartitionsWithIndexRDD[9] at mapPartitionsWithIndex at new_Join_ALS.scala:28
13/06/07 22:25:00 INFO CoGroupedRDD: Adding one-to-one dependency with MappedValuesRDD[146] at mapValues at new_Join_ALS.scala:205
13/06/07 22:25:00 INFO DAGScheduler: Registering RDD 140 (groupByKey at new_Join_ALS.scala:203)
13/06/07 22:25:00 INFO CoGroupedRDD: Adding one-to-one dependency with MapPartitionsWithIndexRDD[11] at mapPartitionsWithIndex at new_Join_ALS.scala:28
13/06/07 22:25:00 INFO CoGroupedRDD: Adding one-to-one dependency with MappedValuesRDD[135] at mapValues at new_Join_ALS.scala:205
13/06/07 22:25:00 INFO DAGScheduler: Registering RDD 129 (groupByKey at new_Join_ALS.scala:203)
13/06/07 22:25:00 INFO CoGroupedRDD: Adding one-to-one dependency with MapPartitionsWithIndexRDD[9] at mapPartitionsWithIndex at new_Join_ALS.scala:28
13/06/07 22:25:00 INFO CoGroupedRDD: Adding one-to-one dependency with MappedValuesRDD[124] at mapValues at new_Join_ALS.scala:205
13/06/07 22:25:00 INFO DAGScheduler: Registering RDD 118 (groupByKey at new_Join_ALS.scala:203)
13/06/07 22:25:00 INFO CoGroupedRDD: Adding one-to-one dependency with MapPartitionsWithIndexRDD[11] at mapPartitionsWithIndex at new_Join_ALS.scala:28
13/06/07 22:25:00 INFO CoGroupedRDD: Adding one-to-one dependency with MappedValuesRDD[113] at mapValues at new_Join_ALS.scala:205
13/06/07 22:25:00 INFO DAGScheduler: Registering RDD 107 (groupByKey at new_Join_ALS.scala:203)
13/06/07 22:25:00 INFO CoGroupedRDD: Adding one-to-one dependency with MapPartitionsWithIndexRDD[9] at mapPartitionsWithIndex at new_Join_ALS.scala:28
13/06/07 22:25:00 INFO CoGroupedRDD: Adding one-to-one dependency with MappedValuesRDD[102] at mapValues at new_Join_ALS.scala:205
13/06/07 22:25:00 INFO DAGScheduler: Registering RDD 96 (groupByKey at new_Join_ALS.scala:203)
13/06/07 22:25:00 INFO CoGroupedRDD: Adding one-to-one dependency with MapPartitionsWithIndexRDD[11] at mapPartitionsWithIndex at new_Join_ALS.scala:28
13/06/07 22:25:00 INFO CoGroupedRDD: Adding one-to-one dependency with MappedValuesRDD[91] at mapValues at new_Join_ALS.scala:205
13/06/07 22:25:00 INFO DAGScheduler: Registering RDD 85 (groupByKey at new_Join_ALS.scala:203)
13/06/07 22:25:00 INFO CoGroupedRDD: Adding one-to-one dependency with MapPartitionsWithIndexRDD[9] at mapPartitionsWithIndex at new_Join_ALS.scala:28
13/06/07 22:25:00 INFO CoGroupedRDD: Adding one-to-one dependency with MappedValuesRDD[80] at mapValues at new_Join_ALS.scala:205
13/06/07 22:25:00 INFO DAGScheduler: Registering RDD 74 (groupByKey at new_Join_ALS.scala:203)
13/06/07 22:25:00 INFO CoGroupedRDD: Adding one-to-one dependency with MapPartitionsWithIndexRDD[11] at mapPartitionsWithIndex at new_Join_ALS.scala:28
13/06/07 22:25:00 INFO CoGroupedRDD: Adding one-to-one dependency with MappedValuesRDD[69] at mapValues at new_Join_ALS.scala:205
13/06/07 22:25:00 INFO DAGScheduler: Registering RDD 63 (groupByKey at new_Join_ALS.scala:203)
13/06/07 22:25:00 INFO CoGroupedRDD: Adding one-to-one dependency with MapPartitionsWithIndexRDD[9] at mapPartitionsWithIndex at new_Join_ALS.scala:28
13/06/07 22:25:00 INFO CoGroupedRDD: Adding one-to-one dependency with MappedValuesRDD[58] at mapValues at new_Join_ALS.scala:205
13/06/07 22:25:00 INFO DAGScheduler: Registering RDD 52 (groupByKey at new_Join_ALS.scala:203)
13/06/07 22:25:00 INFO CoGroupedRDD: Adding one-to-one dependency with MapPartitionsWithIndexRDD[11] at mapPartitionsWithIndex at new_Join_ALS.scala:28
13/06/07 22:25:00 INFO CoGroupedRDD: Adding one-to-one dependency with MappedValuesRDD[47] at mapValues at new_Join_ALS.scala:205
13/06/07 22:25:00 INFO DAGScheduler: Registering RDD 41 (groupByKey at new_Join_ALS.scala:203)
13/06/07 22:25:00 INFO CoGroupedRDD: Adding one-to-one dependency with MapPartitionsWithIndexRDD[9] at mapPartitionsWithIndex at new_Join_ALS.scala:28
13/06/07 22:25:00 INFO CoGroupedRDD: Adding one-to-one dependency with MappedValuesRDD[36] at mapValues at new_Join_ALS.scala:205
13/06/07 22:25:00 INFO DAGScheduler: Registering RDD 30 (groupByKey at new_Join_ALS.scala:203)
13/06/07 22:25:00 INFO CoGroupedRDD: Adding one-to-one dependency with MapPartitionsWithIndexRDD[11] at mapPartitionsWithIndex at new_Join_ALS.scala:28
13/06/07 22:25:00 INFO CoGroupedRDD: Adding one-to-one dependency with MappedValuesRDD[25] at mapValues at new_Join_ALS.scala:205
13/06/07 22:25:00 INFO DAGScheduler: Registering RDD 19 (groupByKey at new_Join_ALS.scala:203)
13/06/07 22:25:00 INFO CoGroupedRDD: Adding one-to-one dependency with MapPartitionsWithIndexRDD[9] at mapPartitionsWithIndex at new_Join_ALS.scala:28
13/06/07 22:25:00 INFO CoGroupedRDD: Adding one-to-one dependency with MappedValuesRDD[13] at mapValues at new_Join_ALS.scala:93
13/06/07 22:25:00 INFO DAGScheduler: Got job 0 (sum at new_Join_ALS.scala:514) with 4 output partitions (allowLocal=false)
13/06/07 22:25:00 INFO DAGScheduler: Final stage: Stage 0 (map at new_Join_ALS.scala:514)
13/06/07 22:25:00 INFO DAGScheduler: Parents of final stage: List(Stage 1, Stage 4)
13/06/07 22:25:00 INFO DAGScheduler: Missing parents: List(Stage 1, Stage 4)
13/06/07 22:25:00 INFO DAGScheduler: Submitting Stage 2 (MappedRDD[7] at map at new_Join_ALS.scala:68), which has no missing parents
13/06/07 22:25:00 INFO DAGScheduler: Submitting 16 missing tasks from Stage 2 (MappedRDD[7] at map at new_Join_ALS.scala:68)
13/06/07 22:25:00 INFO ClusterScheduler: Adding task set 2.0 with 16 tasks
13/06/07 22:25:00 INFO DAGScheduler: Submitting Stage 4 (MappedRDD[5] at map at new_Join_ALS.scala:67), which has no missing parents
13/06/07 22:25:00 INFO DAGScheduler: Submitting 16 missing tasks from Stage 4 (MappedRDD[5] at map at new_Join_ALS.scala:67)
13/06/07 22:25:00 INFO ClusterScheduler: Adding task set 4.0 with 16 tasks
13/06/07 22:25:03 INFO SparkDeploySchedulerBackend: Registered executor: Actor[akka://sparkExecutor@ip-10-232-24-231.ec2.internal:50459/user/Executor] with ID 1
13/06/07 22:25:03 INFO TaskSetManager: Starting task 2.0:0 as TID 0 on executor 1: ip-10-232-24-231.ec2.internal (preferred)
13/06/07 22:25:03 INFO TaskSetManager: Serialized task 2.0:0 as 1915 bytes in 41 ms
13/06/07 22:25:03 INFO TaskSetManager: Starting task 2.0:1 as TID 1 on executor 1: ip-10-232-24-231.ec2.internal (preferred)
13/06/07 22:25:03 INFO TaskSetManager: Serialized task 2.0:1 as 1915 bytes in 0 ms
13/06/07 22:25:03 INFO TaskSetManager: Starting task 2.0:2 as TID 2 on executor 1: ip-10-232-24-231.ec2.internal (preferred)
13/06/07 22:25:03 INFO TaskSetManager: Serialized task 2.0:2 as 1915 bytes in 1 ms
13/06/07 22:25:03 INFO TaskSetManager: Starting task 2.0:3 as TID 3 on executor 1: ip-10-232-24-231.ec2.internal (preferred)
13/06/07 22:25:03 INFO TaskSetManager: Serialized task 2.0:3 as 1915 bytes in 0 ms
13/06/07 22:25:03 INFO TaskSetManager: Starting task 2.0:4 as TID 4 on executor 1: ip-10-232-24-231.ec2.internal (preferred)
13/06/07 22:25:03 INFO TaskSetManager: Serialized task 2.0:4 as 1915 bytes in 0 ms
13/06/07 22:25:03 INFO TaskSetManager: Starting task 2.0:5 as TID 5 on executor 1: ip-10-232-24-231.ec2.internal (preferred)
13/06/07 22:25:03 INFO TaskSetManager: Serialized task 2.0:5 as 1915 bytes in 0 ms
13/06/07 22:25:03 INFO TaskSetManager: Starting task 2.0:6 as TID 6 on executor 1: ip-10-232-24-231.ec2.internal (preferred)
13/06/07 22:25:03 INFO TaskSetManager: Serialized task 2.0:6 as 1915 bytes in 0 ms
13/06/07 22:25:03 INFO TaskSetManager: Starting task 2.0:7 as TID 7 on executor 1: ip-10-232-24-231.ec2.internal (preferred)
13/06/07 22:25:03 INFO TaskSetManager: Serialized task 2.0:7 as 1915 bytes in 1 ms
13/06/07 22:25:03 INFO BlockManagerMasterActor$BlockManagerInfo: Registering block manager ip-10-232-24-231.ec2.internal:33244 with 40.4 GB RAM
13/06/07 22:25:05 INFO SparkDeploySchedulerBackend: Registered executor: Actor[akka://sparkExecutor@ip-10-232-24-207.ec2.internal:59226/user/Executor] with ID 3
13/06/07 22:25:05 INFO TaskSetManager: Starting task 2.0:8 as TID 8 on executor 3: ip-10-232-24-207.ec2.internal (preferred)
13/06/07 22:25:05 INFO TaskSetManager: Serialized task 2.0:8 as 1915 bytes in 0 ms
13/06/07 22:25:05 INFO TaskSetManager: Starting task 2.0:9 as TID 9 on executor 3: ip-10-232-24-207.ec2.internal (preferred)
13/06/07 22:25:05 INFO TaskSetManager: Serialized task 2.0:9 as 1915 bytes in 0 ms
13/06/07 22:25:05 INFO TaskSetManager: Starting task 2.0:10 as TID 10 on executor 3: ip-10-232-24-207.ec2.internal (preferred)
13/06/07 22:25:05 INFO TaskSetManager: Serialized task 2.0:10 as 1915 bytes in 0 ms
13/06/07 22:25:05 INFO TaskSetManager: Starting task 2.0:11 as TID 11 on executor 3: ip-10-232-24-207.ec2.internal (preferred)
13/06/07 22:25:05 INFO TaskSetManager: Serialized task 2.0:11 as 1915 bytes in 0 ms
13/06/07 22:25:05 INFO TaskSetManager: Starting task 2.0:12 as TID 12 on executor 3: ip-10-232-24-207.ec2.internal (preferred)
13/06/07 22:25:05 INFO TaskSetManager: Serialized task 2.0:12 as 1915 bytes in 0 ms
13/06/07 22:25:05 INFO TaskSetManager: Starting task 2.0:13 as TID 13 on executor 3: ip-10-232-24-207.ec2.internal (preferred)
13/06/07 22:25:05 INFO TaskSetManager: Serialized task 2.0:13 as 1915 bytes in 0 ms
13/06/07 22:25:05 INFO TaskSetManager: Starting task 2.0:14 as TID 14 on executor 3: ip-10-232-24-207.ec2.internal (preferred)
13/06/07 22:25:05 INFO TaskSetManager: Serialized task 2.0:14 as 1915 bytes in 1 ms
13/06/07 22:25:05 INFO TaskSetManager: Starting task 2.0:15 as TID 15 on executor 3: ip-10-232-24-207.ec2.internal (preferred)
13/06/07 22:25:05 INFO TaskSetManager: Serialized task 2.0:15 as 1915 bytes in 0 ms
13/06/07 22:25:05 INFO BlockManagerMasterActor$BlockManagerInfo: Registering block manager ip-10-232-24-207.ec2.internal:47865 with 40.4 GB RAM
13/06/07 22:25:08 INFO SparkDeploySchedulerBackend: Registered executor: Actor[akka://sparkExecutor@ip-10-168-23-243.ec2.internal:49637/user/Executor] with ID 2
13/06/07 22:25:08 INFO TaskSetManager: Starting task 4.0:0 as TID 16 on executor 2: ip-10-168-23-243.ec2.internal (preferred)
13/06/07 22:25:08 INFO TaskSetManager: Serialized task 4.0:0 as 1913 bytes in 3 ms
13/06/07 22:25:08 INFO TaskSetManager: Starting task 4.0:1 as TID 17 on executor 2: ip-10-168-23-243.ec2.internal (preferred)
13/06/07 22:25:08 INFO TaskSetManager: Serialized task 4.0:1 as 1913 bytes in 0 ms
13/06/07 22:25:08 INFO TaskSetManager: Starting task 4.0:2 as TID 18 on executor 2: ip-10-168-23-243.ec2.internal (preferred)
13/06/07 22:25:08 INFO TaskSetManager: Serialized task 4.0:2 as 1913 bytes in 0 ms
13/06/07 22:25:08 INFO TaskSetManager: Starting task 4.0:3 as TID 19 on executor 2: ip-10-168-23-243.ec2.internal (preferred)
13/06/07 22:25:08 INFO TaskSetManager: Serialized task 4.0:3 as 1913 bytes in 0 ms
13/06/07 22:25:08 INFO TaskSetManager: Starting task 4.0:4 as TID 20 on executor 2: ip-10-168-23-243.ec2.internal (preferred)
13/06/07 22:25:08 INFO TaskSetManager: Serialized task 4.0:4 as 1913 bytes in 0 ms
13/06/07 22:25:08 INFO TaskSetManager: Starting task 4.0:5 as TID 21 on executor 2: ip-10-168-23-243.ec2.internal (preferred)
13/06/07 22:25:08 INFO TaskSetManager: Serialized task 4.0:5 as 1913 bytes in 0 ms
13/06/07 22:25:08 INFO TaskSetManager: Starting task 4.0:6 as TID 22 on executor 2: ip-10-168-23-243.ec2.internal (preferred)
13/06/07 22:25:08 INFO TaskSetManager: Serialized task 4.0:6 as 1913 bytes in 0 ms
13/06/07 22:25:08 INFO TaskSetManager: Starting task 4.0:7 as TID 23 on executor 2: ip-10-168-23-243.ec2.internal (preferred)
13/06/07 22:25:08 INFO TaskSetManager: Serialized task 4.0:7 as 1913 bytes in 0 ms
13/06/07 22:25:09 INFO BlockManagerMasterActor$BlockManagerInfo: Registering block manager ip-10-168-23-243.ec2.internal:52304 with 40.4 GB RAM
13/06/07 22:27:46 INFO Client$ClientActor: Executor updated: app-20130607222459-0001/0 is now RUNNING
13/06/07 22:27:47 INFO SparkDeploySchedulerBackend: Registered executor: Actor[akka://sparkExecutor@ip-10-29-181-214:54444/user/Executor] with ID 0
13/06/07 22:27:47 INFO TaskSetManager: Starting task 4.0:8 as TID 24 on executor 0: ip-10-29-181-214 (non-preferred, not one of ip-10-232-24-231.ec2.internal, ip-10-168-23-243.ec2.internal, ip-10-232-24-207.ec2.internal)
13/06/07 22:27:47 INFO TaskSetManager: Serialized task 4.0:8 as 1913 bytes in 0 ms
13/06/07 22:27:47 INFO TaskSetManager: Starting task 4.0:9 as TID 25 on executor 0: ip-10-29-181-214 (non-preferred, not one of ip-10-232-24-207.ec2.internal, ip-10-232-24-231.ec2.internal, ip-10-168-23-243.ec2.internal)
13/06/07 22:27:47 INFO TaskSetManager: Serialized task 4.0:9 as 1913 bytes in 1 ms
13/06/07 22:27:47 INFO TaskSetManager: Starting task 4.0:10 as TID 26 on executor 0: ip-10-29-181-214 (non-preferred, not one of ip-10-232-24-207.ec2.internal, ip-10-232-24-231.ec2.internal, ip-10-168-23-243.ec2.internal)
13/06/07 22:27:47 INFO TaskSetManager: Serialized task 4.0:10 as 1913 bytes in 0 ms
13/06/07 22:27:47 INFO TaskSetManager: Starting task 4.0:11 as TID 27 on executor 0: ip-10-29-181-214 (non-preferred, not one of ip-10-232-24-207.ec2.internal, ip-10-168-23-243.ec2.internal, ip-10-232-24-231.ec2.internal)
13/06/07 22:27:47 INFO TaskSetManager: Serialized task 4.0:11 as 1913 bytes in 1 ms
13/06/07 22:27:47 INFO TaskSetManager: Starting task 4.0:12 as TID 28 on executor 0: ip-10-29-181-214 (non-preferred, not one of ip-10-232-24-207.ec2.internal, ip-10-168-23-243.ec2.internal, ip-10-232-24-231.ec2.internal)
13/06/07 22:27:47 INFO TaskSetManager: Serialized task 4.0:12 as 1913 bytes in 0 ms
13/06/07 22:27:47 INFO TaskSetManager: Starting task 4.0:13 as TID 29 on executor 0: ip-10-29-181-214 (non-preferred, not one of ip-10-232-24-207.ec2.internal, ip-10-168-23-243.ec2.internal, ip-10-232-24-231.ec2.internal)
13/06/07 22:27:47 INFO TaskSetManager: Serialized task 4.0:13 as 1913 bytes in 1 ms
13/06/07 22:27:47 INFO TaskSetManager: Starting task 4.0:14 as TID 30 on executor 0: ip-10-29-181-214 (non-preferred, not one of ip-10-168-23-243.ec2.internal, ip-10-232-24-207.ec2.internal, ip-10-232-24-231.ec2.internal)
13/06/07 22:27:47 INFO TaskSetManager: Serialized task 4.0:14 as 1913 bytes in 0 ms
13/06/07 22:27:47 INFO TaskSetManager: Starting task 4.0:15 as TID 31 on executor 0: ip-10-29-181-214 (non-preferred, not one of ip-10-232-24-231.ec2.internal, ip-10-232-24-207.ec2.internal, ip-10-168-23-243.ec2.internal)
13/06/07 22:27:47 INFO TaskSetManager: Serialized task 4.0:15 as 1913 bytes in 1 ms
13/06/07 22:27:47 INFO BlockManagerMasterActor$BlockManagerInfo: Registering block manager ip-10-29-181-214:44625 with 647.7 MB RAM
13/06/07 22:30:10 INFO TaskSetManager: Lost TID 31 (task 4.0:15)
13/06/07 22:30:10 INFO TaskSetManager: Loss was due to java.lang.OutOfMemoryError: GC overhead limit exceeded
	at scala.collection.immutable.StreamIterator.<init>(Stream.scala:936)
	at scala.collection.immutable.Stream.iterator(Stream.scala:510)
	at scala.collection.TraversableLike$class.toIterator(TraversableLike.scala:606)
	at scala.collection.mutable.ArrayOps.toIterator(ArrayOps.scala:38)
	at scala.collection.Iterator$$anon$21.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$class.foreach(Iterator.scala:772)
	at scala.collection.Iterator$$anon$21.foreach(Iterator.scala:437)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:48)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:102)
	at spark.CacheManager.getOrCompute(CacheManager.scala:53)
	at spark.RDD.iterator(RDD.scala:193)
	at spark.rdd.MappedRDD.compute(MappedRDD.scala:12)
	at spark.RDD.computeOrReadCheckpoint(RDD.scala:206)
	at spark.RDD.iterator(RDD.scala:195)
	at spark.scheduler.ShuffleMapTask.run(ShuffleMapTask.scala:125)
	at spark.scheduler.ShuffleMapTask.run(ShuffleMapTask.scala:74)
	at spark.executor.Executor$TaskRunner.run(Executor.scala:101)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1146)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:679)
13/06/07 22:30:10 INFO TaskSetManager: Starting task 4.0:15 as TID 32 on executor 0: ip-10-29-181-214 (non-preferred, not one of ip-10-232-24-231.ec2.internal, ip-10-232-24-207.ec2.internal, ip-10-168-23-243.ec2.internal)
13/06/07 22:30:10 INFO TaskSetManager: Serialized task 4.0:15 as 1913 bytes in 0 ms
13/06/07 22:31:54 INFO TaskSetManager: Lost TID 30 (task 4.0:14)
13/06/07 22:31:54 INFO TaskSetManager: Loss was due to java.lang.OutOfMemoryError: GC overhead limit exceeded
	at scala.collection.immutable.StreamIterator.next(Stream.scala:952)
	at scala.collection.Iterator$$anon$21.next(Iterator.scala:441)
	at scala.collection.Iterator$class.foreach(Iterator.scala:772)
	at scala.collection.Iterator$$anon$21.foreach(Iterator.scala:437)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:48)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:102)
	at spark.CacheManager.getOrCompute(CacheManager.scala:53)
	at spark.RDD.iterator(RDD.scala:193)
	at spark.rdd.MappedRDD.compute(MappedRDD.scala:12)
	at spark.RDD.computeOrReadCheckpoint(RDD.scala:206)
	at spark.RDD.iterator(RDD.scala:195)
	at spark.scheduler.ShuffleMapTask.run(ShuffleMapTask.scala:125)
	at spark.scheduler.ShuffleMapTask.run(ShuffleMapTask.scala:74)
	at spark.executor.Executor$TaskRunner.run(Executor.scala:101)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1146)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:679)
13/06/07 22:31:54 INFO TaskSetManager: Starting task 4.0:14 as TID 33 on executor 0: ip-10-29-181-214 (non-preferred, not one of ip-10-168-23-243.ec2.internal, ip-10-232-24-207.ec2.internal, ip-10-232-24-231.ec2.internal)
13/06/07 22:31:54 INFO TaskSetManager: Serialized task 4.0:14 as 1913 bytes in 0 ms
13/06/07 22:32:50 INFO TaskSetManager: Lost TID 24 (task 4.0:8)
13/06/07 22:32:50 INFO TaskSetManager: Loss was due to java.lang.OutOfMemoryError: Java heap space
	at scala.collection.mutable.ResizableArray$class.ensureSize(ResizableArray.scala:98)
	at scala.collection.mutable.ArrayBuffer.ensureSize(ArrayBuffer.scala:47)
	at scala.collection.mutable.ArrayBuffer.$plus$eq(ArrayBuffer.scala:82)
	at scala.collection.mutable.ArrayBuffer.$plus$eq(ArrayBuffer.scala:47)
	at scala.collection.generic.Growable$$anonfun$$plus$plus$eq$1.apply(Growable.scala:48)
	at scala.collection.generic.Growable$$anonfun$$plus$plus$eq$1.apply(Growable.scala:48)
	at scala.collection.Iterator$class.foreach(Iterator.scala:772)
	at scala.collection.Iterator$$anon$21.foreach(Iterator.scala:437)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:48)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:102)
	at spark.CacheManager.getOrCompute(CacheManager.scala:53)
	at spark.RDD.iterator(RDD.scala:193)
	at spark.rdd.MappedRDD.compute(MappedRDD.scala:12)
	at spark.RDD.computeOrReadCheckpoint(RDD.scala:206)
	at spark.RDD.iterator(RDD.scala:195)
	at spark.scheduler.ShuffleMapTask.run(ShuffleMapTask.scala:125)
	at spark.scheduler.ShuffleMapTask.run(ShuffleMapTask.scala:74)
	at spark.executor.Executor$TaskRunner.run(Executor.scala:101)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1146)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:679)
13/06/07 22:32:50 INFO TaskSetManager: Starting task 4.0:8 as TID 34 on executor 0: ip-10-29-181-214 (non-preferred, not one of ip-10-232-24-231.ec2.internal, ip-10-168-23-243.ec2.internal, ip-10-232-24-207.ec2.internal)
13/06/07 22:32:50 INFO TaskSetManager: Serialized task 4.0:8 as 1913 bytes in 0 ms
13/06/07 22:34:42 INFO TaskSetManager: Lost TID 33 (task 4.0:14)
13/06/07 22:34:42 INFO TaskSetManager: Loss was due to java.lang.OutOfMemoryError: GC overhead limit exceeded
	at java.lang.Double.valueOf(Double.java:509)
	at scala.runtime.BoxesRunTime.boxToDouble(Unknown Source)
	at als_debug.Join_ALS$$anonfun$main$2.apply(new_Join_ALS.scala:490)
	at als_debug.Join_ALS$$anonfun$main$2.apply(new_Join_ALS.scala:490)
	at scala.collection.Iterator$$anon$19.next(Iterator.scala:401)
	at scala.collection.Iterator$$anon$21.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$class.foreach(Iterator.scala:772)
	at scala.collection.Iterator$$anon$21.foreach(Iterator.scala:437)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:48)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:102)
	at spark.CacheManager.getOrCompute(CacheManager.scala:53)
	at spark.RDD.iterator(RDD.scala:193)
	at spark.rdd.MappedRDD.compute(MappedRDD.scala:12)
	at spark.RDD.computeOrReadCheckpoint(RDD.scala:206)
	at spark.RDD.iterator(RDD.scala:195)
	at spark.scheduler.ShuffleMapTask.run(ShuffleMapTask.scala:125)
	at spark.scheduler.ShuffleMapTask.run(ShuffleMapTask.scala:74)
	at spark.executor.Executor$TaskRunner.run(Executor.scala:101)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1146)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:679)
13/06/07 22:34:42 INFO TaskSetManager: Starting task 4.0:14 as TID 35 on executor 0: ip-10-29-181-214 (non-preferred, not one of ip-10-168-23-243.ec2.internal, ip-10-232-24-207.ec2.internal, ip-10-232-24-231.ec2.internal)
13/06/07 22:34:42 INFO TaskSetManager: Serialized task 4.0:14 as 1913 bytes in 0 ms
13/06/07 22:35:44 INFO TaskSetManager: Lost TID 34 (task 4.0:8)
13/06/07 22:35:44 INFO TaskSetManager: Loss was due to java.lang.OutOfMemoryError: GC overhead limit exceeded

13/06/07 22:35:44 INFO TaskSetManager: Starting task 4.0:8 as TID 36 on executor 0: ip-10-29-181-214 (non-preferred, not one of ip-10-232-24-231.ec2.internal, ip-10-168-23-243.ec2.internal, ip-10-232-24-207.ec2.internal)
13/06/07 22:35:44 INFO TaskSetManager: Serialized task 4.0:8 as 1913 bytes in 1 ms
13/06/07 22:35:44 INFO TaskSetManager: Lost TID 32 (task 4.0:15)
13/06/07 22:35:44 INFO TaskSetManager: Loss was due to java.lang.OutOfMemoryError: GC overhead limit exceeded [duplicate 1]
13/06/07 22:35:44 INFO TaskSetManager: Starting task 4.0:15 as TID 37 on executor 0: ip-10-29-181-214 (non-preferred, not one of ip-10-232-24-231.ec2.internal, ip-10-232-24-207.ec2.internal, ip-10-168-23-243.ec2.internal)
13/06/07 22:35:44 INFO TaskSetManager: Serialized task 4.0:15 as 1913 bytes in 0 ms
13/06/07 22:37:42 INFO SparkDeploySchedulerBackend: Executor 0 disconnected, so removing it
13/06/07 22:37:42 ERROR ClusterScheduler: Lost executor 0 on ip-10-29-181-214: remote Akka client shutdown
13/06/07 22:37:42 INFO TaskSetManager: Re-queueing tasks for 0 from TaskSet 2.0
13/06/07 22:37:42 INFO Client$ClientActor: Executor updated: app-20130607222459-0001/0 is now FAILED (Command exited with code 52)
13/06/07 22:37:42 INFO SparkDeploySchedulerBackend: Executor app-20130607222459-0001/0 removed: Command exited with code 52
13/06/07 22:37:42 INFO TaskSetManager: Re-queueing tasks for 0 from TaskSet 4.0
13/06/07 22:37:42 INFO TaskSetManager: Lost TID 35 (task 4.0:14)
13/06/07 22:37:42 INFO TaskSetManager: Lost TID 37 (task 4.0:15)
13/06/07 22:37:42 INFO TaskSetManager: Lost TID 26 (task 4.0:10)
13/06/07 22:37:42 INFO TaskSetManager: Lost TID 29 (task 4.0:13)
13/06/07 22:37:42 INFO TaskSetManager: Lost TID 25 (task 4.0:9)
13/06/07 22:37:42 INFO TaskSetManager: Lost TID 27 (task 4.0:11)
13/06/07 22:37:42 INFO TaskSetManager: Lost TID 36 (task 4.0:8)
13/06/07 22:37:42 INFO TaskSetManager: Lost TID 28 (task 4.0:12)
13/06/07 22:37:42 INFO Client$ClientActor: Executor added: app-20130607222459-0001/4 on worker-20130607204453-ip-10-29-181-214-59792 (ip-10-29-181-214) with 8 cores
13/06/07 22:37:42 INFO SparkDeploySchedulerBackend: Granted executor ID app-20130607222459-0001/4 on host ip-10-29-181-214 with 8 cores, 40.0 GB RAM
13/06/07 22:37:42 INFO DAGScheduler: Executor lost: 0 (generation 0)
13/06/07 22:37:42 INFO BlockManagerMasterActor: Trying to remove executor 0 from BlockManagerMaster.
13/06/07 22:37:42 INFO BlockManagerMaster: Removed 0 successfully in removeExecutor
13/06/07 22:37:42 INFO Client$ClientActor: Executor updated: app-20130607222459-0001/4 is now RUNNING
13/06/07 22:37:44 INFO SparkDeploySchedulerBackend: Registered executor: Actor[akka://sparkExecutor@ip-10-29-181-214:43724/user/Executor] with ID 4
13/06/07 22:37:44 INFO TaskSetManager: Starting task 4.0:12 as TID 38 on executor 4: ip-10-29-181-214 (non-preferred, not one of ip-10-232-24-207.ec2.internal, ip-10-168-23-243.ec2.internal, ip-10-232-24-231.ec2.internal)
13/06/07 22:37:44 INFO TaskSetManager: Serialized task 4.0:12 as 1913 bytes in 0 ms
13/06/07 22:37:44 INFO TaskSetManager: Starting task 4.0:8 as TID 39 on executor 4: ip-10-29-181-214 (non-preferred, not one of ip-10-232-24-231.ec2.internal, ip-10-168-23-243.ec2.internal, ip-10-232-24-207.ec2.internal)
13/06/07 22:37:44 INFO TaskSetManager: Serialized task 4.0:8 as 1913 bytes in 0 ms
13/06/07 22:37:44 INFO TaskSetManager: Starting task 4.0:11 as TID 40 on executor 4: ip-10-29-181-214 (non-preferred, not one of ip-10-232-24-207.ec2.internal, ip-10-168-23-243.ec2.internal, ip-10-232-24-231.ec2.internal)
13/06/07 22:37:44 INFO TaskSetManager: Serialized task 4.0:11 as 1913 bytes in 0 ms
13/06/07 22:37:44 INFO TaskSetManager: Starting task 4.0:9 as TID 41 on executor 4: ip-10-29-181-214 (non-preferred, not one of ip-10-232-24-207.ec2.internal, ip-10-232-24-231.ec2.internal, ip-10-168-23-243.ec2.internal)
13/06/07 22:37:44 INFO TaskSetManager: Serialized task 4.0:9 as 1913 bytes in 0 ms
13/06/07 22:37:44 INFO TaskSetManager: Starting task 4.0:13 as TID 42 on executor 4: ip-10-29-181-214 (non-preferred, not one of ip-10-232-24-207.ec2.internal, ip-10-168-23-243.ec2.internal, ip-10-232-24-231.ec2.internal)
13/06/07 22:37:44 INFO TaskSetManager: Serialized task 4.0:13 as 1913 bytes in 0 ms
13/06/07 22:37:44 INFO TaskSetManager: Starting task 4.0:10 as TID 43 on executor 4: ip-10-29-181-214 (non-preferred, not one of ip-10-232-24-207.ec2.internal, ip-10-232-24-231.ec2.internal, ip-10-168-23-243.ec2.internal)
13/06/07 22:37:44 INFO TaskSetManager: Serialized task 4.0:10 as 1913 bytes in 0 ms
13/06/07 22:37:44 INFO TaskSetManager: Starting task 4.0:15 as TID 44 on executor 4: ip-10-29-181-214 (non-preferred, not one of ip-10-232-24-231.ec2.internal, ip-10-232-24-207.ec2.internal, ip-10-168-23-243.ec2.internal)
13/06/07 22:37:44 INFO TaskSetManager: Serialized task 4.0:15 as 1913 bytes in 0 ms
13/06/07 22:37:44 INFO TaskSetManager: Starting task 4.0:14 as TID 45 on executor 4: ip-10-29-181-214 (non-preferred, not one of ip-10-168-23-243.ec2.internal, ip-10-232-24-207.ec2.internal, ip-10-232-24-231.ec2.internal)
13/06/07 22:37:44 INFO TaskSetManager: Serialized task 4.0:14 as 1913 bytes in 0 ms
13/06/07 22:37:44 INFO BlockManagerMasterActor$BlockManagerInfo: Registering block manager ip-10-29-181-214:50390 with 647.7 MB RAM
13/06/07 22:40:04 INFO TaskSetManager: Lost TID 40 (task 4.0:11)
13/06/07 22:40:04 INFO TaskSetManager: Loss was due to java.lang.OutOfMemoryError: GC overhead limit exceeded
	at scala.collection.immutable.StreamIterator.next(Stream.scala:952)
	at scala.collection.Iterator$$anon$21.next(Iterator.scala:441)
	at scala.collection.Iterator$class.foreach(Iterator.scala:772)
	at scala.collection.Iterator$$anon$21.foreach(Iterator.scala:437)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:48)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:102)
	at spark.CacheManager.getOrCompute(CacheManager.scala:53)
	at spark.RDD.iterator(RDD.scala:193)
	at spark.rdd.MappedRDD.compute(MappedRDD.scala:12)
	at spark.RDD.computeOrReadCheckpoint(RDD.scala:206)
	at spark.RDD.iterator(RDD.scala:195)
	at spark.scheduler.ShuffleMapTask.run(ShuffleMapTask.scala:125)
	at spark.scheduler.ShuffleMapTask.run(ShuffleMapTask.scala:74)
	at spark.executor.Executor$TaskRunner.run(Executor.scala:101)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1146)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:679)
13/06/07 22:40:04 INFO TaskSetManager: Starting task 4.0:11 as TID 46 on executor 4: ip-10-29-181-214 (non-preferred, not one of ip-10-232-24-207.ec2.internal, ip-10-168-23-243.ec2.internal, ip-10-232-24-231.ec2.internal)
13/06/07 22:40:04 INFO TaskSetManager: Serialized task 4.0:11 as 1913 bytes in 0 ms
13/06/07 22:41:50 INFO TaskSetManager: Lost TID 45 (task 4.0:14)
13/06/07 22:41:50 INFO TaskSetManager: Loss was due to java.lang.OutOfMemoryError: GC overhead limit exceeded
	at scala.collection.immutable.StreamIterator.next(Stream.scala:952)
	at scala.collection.Iterator$$anon$21.next(Iterator.scala:441)
	at scala.collection.Iterator$class.foreach(Iterator.scala:772)
	at scala.collection.Iterator$$anon$21.foreach(Iterator.scala:437)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:48)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:102)
	at spark.CacheManager.getOrCompute(CacheManager.scala:53)
	at spark.RDD.iterator(RDD.scala:193)
	at spark.rdd.MappedRDD.compute(MappedRDD.scala:12)
	at spark.RDD.computeOrReadCheckpoint(RDD.scala:206)
	at spark.RDD.iterator(RDD.scala:195)
	at spark.scheduler.ShuffleMapTask.run(ShuffleMapTask.scala:125)
	at spark.scheduler.ShuffleMapTask.run(ShuffleMapTask.scala:74)
	at spark.executor.Executor$TaskRunner.run(Executor.scala:101)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1146)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:679)
13/06/07 22:41:50 INFO TaskSetManager: Starting task 4.0:14 as TID 47 on executor 4: ip-10-29-181-214 (non-preferred, not one of ip-10-168-23-243.ec2.internal, ip-10-232-24-207.ec2.internal, ip-10-232-24-231.ec2.internal)
13/06/07 22:41:50 INFO TaskSetManager: Serialized task 4.0:14 as 1913 bytes in 0 ms
13/06/07 22:42:28 INFO TaskSetManager: Lost TID 43 (task 4.0:10)
13/06/07 22:42:28 INFO TaskSetManager: Loss was due to java.lang.OutOfMemoryError: Java heap space
	at scala.collection.mutable.ResizableArray$class.ensureSize(ResizableArray.scala:98)
	at scala.collection.mutable.ArrayBuffer.ensureSize(ArrayBuffer.scala:47)
	at scala.collection.mutable.ArrayBuffer.$plus$eq(ArrayBuffer.scala:82)
	at scala.collection.mutable.ArrayBuffer.$plus$eq(ArrayBuffer.scala:47)
	at scala.collection.generic.Growable$$anonfun$$plus$plus$eq$1.apply(Growable.scala:48)
	at scala.collection.generic.Growable$$anonfun$$plus$plus$eq$1.apply(Growable.scala:48)
	at scala.collection.Iterator$class.foreach(Iterator.scala:772)
	at scala.collection.Iterator$$anon$21.foreach(Iterator.scala:437)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:48)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:102)
	at spark.CacheManager.getOrCompute(CacheManager.scala:53)
	at spark.RDD.iterator(RDD.scala:193)
	at spark.rdd.MappedRDD.compute(MappedRDD.scala:12)
	at spark.RDD.computeOrReadCheckpoint(RDD.scala:206)
	at spark.RDD.iterator(RDD.scala:195)
	at spark.scheduler.ShuffleMapTask.run(ShuffleMapTask.scala:125)
	at spark.scheduler.ShuffleMapTask.run(ShuffleMapTask.scala:74)
	at spark.executor.Executor$TaskRunner.run(Executor.scala:101)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1146)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:679)
13/06/07 22:42:28 INFO TaskSetManager: Starting task 4.0:10 as TID 48 on executor 4: ip-10-29-181-214 (non-preferred, not one of ip-10-232-24-207.ec2.internal, ip-10-232-24-231.ec2.internal, ip-10-168-23-243.ec2.internal)
13/06/07 22:42:28 INFO TaskSetManager: Serialized task 4.0:10 as 1913 bytes in 0 ms
13/06/07 22:46:12 INFO TaskSetManager: Lost TID 6 (task 2.0:6)
13/06/07 22:46:12 INFO TaskSetManager: Loss was due to java.lang.OutOfMemoryError: Java heap space
	at scala.collection.mutable.ResizableArray$class.ensureSize(ResizableArray.scala:98)
	at scala.collection.mutable.ArrayBuffer.ensureSize(ArrayBuffer.scala:47)
	at scala.collection.mutable.ArrayBuffer.$plus$eq(ArrayBuffer.scala:82)
	at scala.collection.mutable.ArrayBuffer.$plus$eq(ArrayBuffer.scala:47)
	at scala.collection.generic.Growable$$anonfun$$plus$plus$eq$1.apply(Growable.scala:48)
	at scala.collection.generic.Growable$$anonfun$$plus$plus$eq$1.apply(Growable.scala:48)
	at scala.collection.Iterator$class.foreach(Iterator.scala:772)
	at scala.collection.Iterator$$anon$21.foreach(Iterator.scala:437)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:48)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:102)
	at spark.CacheManager.getOrCompute(CacheManager.scala:53)
	at spark.RDD.iterator(RDD.scala:193)
	at spark.rdd.MappedRDD.compute(MappedRDD.scala:12)
	at spark.RDD.computeOrReadCheckpoint(RDD.scala:206)
	at spark.RDD.iterator(RDD.scala:195)
	at spark.scheduler.ShuffleMapTask.run(ShuffleMapTask.scala:125)
	at spark.scheduler.ShuffleMapTask.run(ShuffleMapTask.scala:74)
	at spark.executor.Executor$TaskRunner.run(Executor.scala:101)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1146)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:679)
13/06/07 22:46:12 INFO TaskSetManager: Starting task 2.0:6 as TID 49 on executor 1: ip-10-232-24-231.ec2.internal (preferred)
13/06/07 22:46:12 INFO TaskSetManager: Serialized task 2.0:6 as 1915 bytes in 1 ms
